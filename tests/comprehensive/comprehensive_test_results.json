{
  "test_date": "2025-08-24T17:42:02.230719",
  "overall_status": "success",
  "test_summary": {
    "general_tests": {
      "total_tests": 43,
      "successful_tests": 42,
      "failed_tests": 1,
      "success_rate": 97.67441860465115,
      "overall_status": "partial_failure",
      "performance_metrics": {
        "avg_response_time_ms": 55.67960739135742,
        "min_response_time_ms": 52.11067199707031,
        "max_response_time_ms": 62.14761734008789,
        "response_time_std_dev": 4.046639349853329,
        "avg_results_per_query": 10
      },
      "test_categories": [
        "basic_queries",
        "semantic_queries",
        "score_thresholds",
        "result_limits",
        "file_types",
        "performance",
        "error_cases"
      ]
    },
    "tree_sitter_tests": {}
  },
  "detailed_results": {
    "general": {
      "basic_queries": [
        {
          "test_type": "basic",
          "query": "search",
          "min_score": 0.1,
          "max_results": 10,
          "status": "success",
          "results_count": 10,
          "valid_results_count": 10,
          "response_time": 51.358938217163086,
          "timestamp": "2025-08-24T17:41:59.411242",
          "results_sample": [
            {
              "id": "6321a5d0-2edc-51bc-8d83-58f3565d3348",
              "score": 0.45283544,
              "payload": {
                "filePath": "batch_config.json",
                "codeChunk": "\"ollama_model\": \"dengcao/Qwen3-Embedding-0.6B:F16\"",
                "startLine": 3,
                "endLine": 3,
                "type": "pair"
              }
            },
            {
              "id": "53cbb6db-63df-5702-9749-47821640e26d",
              "score": 0.45283544,
              "payload": {
                "filePath": "search_with_original_model.json",
                "codeChunk": "\"ollama_model\": \"dengcao/Qwen3-Embedding-0.6B:F16\"",
                "startLine": 4,
                "endLine": 4,
                "type": "pair"
              }
            },
            {
              "id": "8168407b-c422-5f6f-b7bf-e41c58fac0fb",
              "score": 0.45283544,
              "payload": {
                "filePath": "code_index.json",
                "codeChunk": "\"ollama_model\": \"dengcao/Qwen3-Embedding-0.6B:F16\"",
                "startLine": 4,
                "endLine": 4,
                "type": "pair"
              }
            }
          ]
        },
        {
          "test_type": "basic",
          "query": "function",
          "min_score": 0.1,
          "max_results": 10,
          "status": "success",
          "results_count": 10,
          "valid_results_count": 10,
          "response_time": 60.95242500305176,
          "timestamp": "2025-08-24T17:41:59.472229",
          "results_sample": [
            {
              "id": "e291927d-397c-5da3-8234-6494748cb314",
              "score": 0.3995579,
              "payload": {
                "filePath": "docs/README.md",
                "codeChunk": "\n2. **Code Parsing**: Files are parsed into meaningful code blocks. For now, a simple line-based chunking approach is used, but this could be enhanced with tree-sitter parsing in the future.\n\n3. **Embedding Generation**: Ollama is used to generate vector embeddings for each code block.\n\n4. **Vector Storage**: Embeddings are stored in Qdrant with metadata about the file path, line numbers, and content.\n\n5. **Caching**: File hashes are cached to avoid reprocessing unchanged files.\n\n6. **Search**: Semantic search is performed by generating an embedding for the query and finding similar vectors in Qdrant.\n\n## Example Workflow\n\n```bash\n# Index your codebase\ncode-index index --workspace /path/to/your/project\n\n# Search for specific functionality\ncode-index search \"database connection function\"\n\n# Search with custom parameters\ncode-index search \"API endpoint\" --min-score 0.5 --max-results 20\n```\n\n## Development\n\nFor development and testing scripts, see the `scripts/` directory and documentation in `docs/development/`.\n\n## License\n\nMIT\n## Advanced Features\n\n### Config-first Embedding Length\n- You must set a dimension that matches your embedding model:",
                "startLine": 129,
                "endLine": 163,
                "type": "chunk"
              }
            },
            {
              "id": "b62d7806-cd56-50c3-8343-fd951a77359d",
              "score": 0.3981247,
              "payload": {
                "filePath": "scripts/run/run_env_check.py",
                "codeChunk": "def run_env_verification():\n    \"\"\"Run the environment verification.\"\"\"\n    print(\"Running environment verification for Code Index Tool\")\n    print(\"==============================================\")\n    \n    if os.path.exists(\"verify_env.py\"):\n        print(\"Starting environment verification...\")\n        result = subprocess.run(['python', 'verify_env.py'])\n        if result.returncode == 0:\n            print(\"\u2713 Environment verification completed successfully\")\n            return True\n        else:\n            print(\"\u2717 Environment verification failed\")\n            return False\n    else:\n        print(\"\u2717 verify_env.py not found\")\n        return False\n\n\ndef",
                "startLine": 10,
                "endLine": 26,
                "type": "function_definition"
              }
            },
            {
              "id": "94e356aa-66b6-53e6-a388-8308d091785e",
              "score": 0.37110496,
              "payload": {
                "filePath": "scripts/run/run_benchmark.py",
                "codeChunk": "def run_benchmark():\n    \"\"\"Run the benchmark.\"\"\"\n    print(\"Running benchmark for Code Index Tool\")\n    print(\"=================================\")\n    \n    if os.path.exists(\"benchmark.py\"):\n        print(\"Starting benchmark...\")\n        result = subprocess.run(['python', 'benchmark.py'])\n        if result.returncode == 0:\n            print(\"\u2713 Benchmark completed successfully\")\n            return True\n        else:\n            print(\"\u2717 Benchmark failed\")\n            return False\n    else:\n        print(\"\u2717 benchmark.py not found\")\n        return False\n\n\ndef",
                "startLine": 10,
                "endLine": 26,
                "type": "function_definition"
              }
            }
          ]
        },
        {
          "test_type": "basic",
          "query": "class",
          "min_score": 0.1,
          "max_results": 10,
          "status": "success",
          "results_count": 10,
          "valid_results_count": 10,
          "response_time": 61.936378479003906,
          "timestamp": "2025-08-24T17:41:59.534215",
          "results_sample": [
            {
              "id": "b62d7806-cd56-50c3-8343-fd951a77359d",
              "score": 0.3890106,
              "payload": {
                "filePath": "scripts/run/run_env_check.py",
                "codeChunk": "def run_env_verification():\n    \"\"\"Run the environment verification.\"\"\"\n    print(\"Running environment verification for Code Index Tool\")\n    print(\"==============================================\")\n    \n    if os.path.exists(\"verify_env.py\"):\n        print(\"Starting environment verification...\")\n        result = subprocess.run(['python', 'verify_env.py'])\n        if result.returncode == 0:\n            print(\"\u2713 Environment verification completed successfully\")\n            return True\n        else:\n            print(\"\u2717 Environment verification failed\")\n            return False\n    else:\n        print(\"\u2717 verify_env.py not found\")\n        return False\n\n\ndef",
                "startLine": 10,
                "endLine": 26,
                "type": "function_definition"
              }
            },
            {
              "id": "e291927d-397c-5da3-8234-6494748cb314",
              "score": 0.38753754,
              "payload": {
                "filePath": "docs/README.md",
                "codeChunk": "\n2. **Code Parsing**: Files are parsed into meaningful code blocks. For now, a simple line-based chunking approach is used, but this could be enhanced with tree-sitter parsing in the future.\n\n3. **Embedding Generation**: Ollama is used to generate vector embeddings for each code block.\n\n4. **Vector Storage**: Embeddings are stored in Qdrant with metadata about the file path, line numbers, and content.\n\n5. **Caching**: File hashes are cached to avoid reprocessing unchanged files.\n\n6. **Search**: Semantic search is performed by generating an embedding for the query and finding similar vectors in Qdrant.\n\n## Example Workflow\n\n```bash\n# Index your codebase\ncode-index index --workspace /path/to/your/project\n\n# Search for specific functionality\ncode-index search \"database connection function\"\n\n# Search with custom parameters\ncode-index search \"API endpoint\" --min-score 0.5 --max-results 20\n```\n\n## Development\n\nFor development and testing scripts, see the `scripts/` directory and documentation in `docs/development/`.\n\n## License\n\nMIT\n## Advanced Features\n\n### Config-first Embedding Length\n- You must set a dimension that matches your embedding model:",
                "startLine": 129,
                "endLine": 163,
                "type": "chunk"
              }
            },
            {
              "id": "bebb0a11-3a42-593a-a198-c7d79341ea93",
              "score": 0.37641048,
              "payload": {
                "filePath": "kanban_api_config.json",
                "codeChunk": "\"ollama_model\": \"dengcao/Qwen3-Embedding-0.6B:F16\"",
                "startLine": 4,
                "endLine": 4,
                "type": "pair"
              }
            }
          ]
        },
        {
          "test_type": "basic",
          "query": "test",
          "min_score": 0.1,
          "max_results": 10,
          "status": "success",
          "results_count": 10,
          "valid_results_count": 10,
          "response_time": 52.74629592895508,
          "timestamp": "2025-08-24T17:41:59.586995",
          "results_sample": [
            {
              "id": "53cbb6db-63df-5702-9749-47821640e26d",
              "score": 0.4197765,
              "payload": {
                "filePath": "search_with_original_model.json",
                "codeChunk": "\"ollama_model\": \"dengcao/Qwen3-Embedding-0.6B:F16\"",
                "startLine": 4,
                "endLine": 4,
                "type": "pair"
              }
            },
            {
              "id": "bebb0a11-3a42-593a-a198-c7d79341ea93",
              "score": 0.4197765,
              "payload": {
                "filePath": "kanban_api_config.json",
                "codeChunk": "\"ollama_model\": \"dengcao/Qwen3-Embedding-0.6B:F16\"",
                "startLine": 4,
                "endLine": 4,
                "type": "pair"
              }
            },
            {
              "id": "6321a5d0-2edc-51bc-8d83-58f3565d3348",
              "score": 0.4197765,
              "payload": {
                "filePath": "batch_config.json",
                "codeChunk": "\"ollama_model\": \"dengcao/Qwen3-Embedding-0.6B:F16\"",
                "startLine": 3,
                "endLine": 3,
                "type": "pair"
              }
            }
          ]
        },
        {
          "test_type": "basic",
          "query": "import",
          "min_score": 0.1,
          "max_results": 10,
          "status": "success",
          "results_count": 10,
          "valid_results_count": 10,
          "response_time": 55.904388427734375,
          "timestamp": "2025-08-24T17:41:59.642925",
          "results_sample": [
            {
              "id": "b62d7806-cd56-50c3-8343-fd951a77359d",
              "score": 0.42543346,
              "payload": {
                "filePath": "scripts/run/run_env_check.py",
                "codeChunk": "def run_env_verification():\n    \"\"\"Run the environment verification.\"\"\"\n    print(\"Running environment verification for Code Index Tool\")\n    print(\"==============================================\")\n    \n    if os.path.exists(\"verify_env.py\"):\n        print(\"Starting environment verification...\")\n        result = subprocess.run(['python', 'verify_env.py'])\n        if result.returncode == 0:\n            print(\"\u2713 Environment verification completed successfully\")\n            return True\n        else:\n            print(\"\u2717 Environment verification failed\")\n            return False\n    else:\n        print(\"\u2717 verify_env.py not found\")\n        return False\n\n\ndef",
                "startLine": 10,
                "endLine": 26,
                "type": "function_definition"
              }
            },
            {
              "id": "e291927d-397c-5da3-8234-6494748cb314",
              "score": 0.41833213,
              "payload": {
                "filePath": "docs/README.md",
                "codeChunk": "\n2. **Code Parsing**: Files are parsed into meaningful code blocks. For now, a simple line-based chunking approach is used, but this could be enhanced with tree-sitter parsing in the future.\n\n3. **Embedding Generation**: Ollama is used to generate vector embeddings for each code block.\n\n4. **Vector Storage**: Embeddings are stored in Qdrant with metadata about the file path, line numbers, and content.\n\n5. **Caching**: File hashes are cached to avoid reprocessing unchanged files.\n\n6. **Search**: Semantic search is performed by generating an embedding for the query and finding similar vectors in Qdrant.\n\n## Example Workflow\n\n```bash\n# Index your codebase\ncode-index index --workspace /path/to/your/project\n\n# Search for specific functionality\ncode-index search \"database connection function\"\n\n# Search with custom parameters\ncode-index search \"API endpoint\" --min-score 0.5 --max-results 20\n```\n\n## Development\n\nFor development and testing scripts, see the `scripts/` directory and documentation in `docs/development/`.\n\n## License\n\nMIT\n## Advanced Features\n\n### Config-first Embedding Length\n- You must set a dimension that matches your embedding model:",
                "startLine": 129,
                "endLine": 163,
                "type": "chunk"
              }
            },
            {
              "id": "bebb0a11-3a42-593a-a198-c7d79341ea93",
              "score": 0.41685188,
              "payload": {
                "filePath": "kanban_api_config.json",
                "codeChunk": "\"ollama_model\": \"dengcao/Qwen3-Embedding-0.6B:F16\"",
                "startLine": 4,
                "endLine": 4,
                "type": "pair"
              }
            }
          ]
        },
        {
          "test_type": "basic",
          "query": "export",
          "min_score": 0.1,
          "max_results": 10,
          "status": "success",
          "results_count": 10,
          "valid_results_count": 10,
          "response_time": 51.795244216918945,
          "timestamp": "2025-08-24T17:41:59.694753",
          "results_sample": [
            {
              "id": "53cbb6db-63df-5702-9749-47821640e26d",
              "score": 0.45734358,
              "payload": {
                "filePath": "search_with_original_model.json",
                "codeChunk": "\"ollama_model\": \"dengcao/Qwen3-Embedding-0.6B:F16\"",
                "startLine": 4,
                "endLine": 4,
                "type": "pair"
              }
            },
            {
              "id": "8168407b-c422-5f6f-b7bf-e41c58fac0fb",
              "score": 0.45734358,
              "payload": {
                "filePath": "code_index.json",
                "codeChunk": "\"ollama_model\": \"dengcao/Qwen3-Embedding-0.6B:F16\"",
                "startLine": 4,
                "endLine": 4,
                "type": "pair"
              }
            },
            {
              "id": "6321a5d0-2edc-51bc-8d83-58f3565d3348",
              "score": 0.45734358,
              "payload": {
                "filePath": "batch_config.json",
                "codeChunk": "\"ollama_model\": \"dengcao/Qwen3-Embedding-0.6B:F16\"",
                "startLine": 3,
                "endLine": 3,
                "type": "pair"
              }
            }
          ]
        },
        {
          "test_type": "basic",
          "query": "return",
          "min_score": 0.1,
          "max_results": 10,
          "status": "success",
          "results_count": 10,
          "valid_results_count": 10,
          "response_time": 52.34646797180176,
          "timestamp": "2025-08-24T17:41:59.747130",
          "results_sample": [
            {
              "id": "6321a5d0-2edc-51bc-8d83-58f3565d3348",
              "score": 0.45328754,
              "payload": {
                "filePath": "batch_config.json",
                "codeChunk": "\"ollama_model\": \"dengcao/Qwen3-Embedding-0.6B:F16\"",
                "startLine": 3,
                "endLine": 3,
                "type": "pair"
              }
            },
            {
              "id": "8168407b-c422-5f6f-b7bf-e41c58fac0fb",
              "score": 0.45328754,
              "payload": {
                "filePath": "code_index.json",
                "codeChunk": "\"ollama_model\": \"dengcao/Qwen3-Embedding-0.6B:F16\"",
                "startLine": 4,
                "endLine": 4,
                "type": "pair"
              }
            },
            {
              "id": "53cbb6db-63df-5702-9749-47821640e26d",
              "score": 0.45328754,
              "payload": {
                "filePath": "search_with_original_model.json",
                "codeChunk": "\"ollama_model\": \"dengcao/Qwen3-Embedding-0.6B:F16\"",
                "startLine": 4,
                "endLine": 4,
                "type": "pair"
              }
            }
          ]
        },
        {
          "test_type": "basic",
          "query": "def",
          "min_score": 0.1,
          "max_results": 10,
          "status": "success",
          "results_count": 10,
          "valid_results_count": 10,
          "response_time": 57.407379150390625,
          "timestamp": "2025-08-24T17:41:59.804562",
          "results_sample": [
            {
              "id": "b62d7806-cd56-50c3-8343-fd951a77359d",
              "score": 0.4019953,
              "payload": {
                "filePath": "scripts/run/run_env_check.py",
                "codeChunk": "def run_env_verification():\n    \"\"\"Run the environment verification.\"\"\"\n    print(\"Running environment verification for Code Index Tool\")\n    print(\"==============================================\")\n    \n    if os.path.exists(\"verify_env.py\"):\n        print(\"Starting environment verification...\")\n        result = subprocess.run(['python', 'verify_env.py'])\n        if result.returncode == 0:\n            print(\"\u2713 Environment verification completed successfully\")\n            return True\n        else:\n            print(\"\u2717 Environment verification failed\")\n            return False\n    else:\n        print(\"\u2717 verify_env.py not found\")\n        return False\n\n\ndef",
                "startLine": 10,
                "endLine": 26,
                "type": "function_definition"
              }
            },
            {
              "id": "e291927d-397c-5da3-8234-6494748cb314",
              "score": 0.3938451,
              "payload": {
                "filePath": "docs/README.md",
                "codeChunk": "\n2. **Code Parsing**: Files are parsed into meaningful code blocks. For now, a simple line-based chunking approach is used, but this could be enhanced with tree-sitter parsing in the future.\n\n3. **Embedding Generation**: Ollama is used to generate vector embeddings for each code block.\n\n4. **Vector Storage**: Embeddings are stored in Qdrant with metadata about the file path, line numbers, and content.\n\n5. **Caching**: File hashes are cached to avoid reprocessing unchanged files.\n\n6. **Search**: Semantic search is performed by generating an embedding for the query and finding similar vectors in Qdrant.\n\n## Example Workflow\n\n```bash\n# Index your codebase\ncode-index index --workspace /path/to/your/project\n\n# Search for specific functionality\ncode-index search \"database connection function\"\n\n# Search with custom parameters\ncode-index search \"API endpoint\" --min-score 0.5 --max-results 20\n```\n\n## Development\n\nFor development and testing scripts, see the `scripts/` directory and documentation in `docs/development/`.\n\n## License\n\nMIT\n## Advanced Features\n\n### Config-first Embedding Length\n- You must set a dimension that matches your embedding model:",
                "startLine": 129,
                "endLine": 163,
                "type": "chunk"
              }
            },
            {
              "id": "94e356aa-66b6-53e6-a388-8308d091785e",
              "score": 0.37792256,
              "payload": {
                "filePath": "scripts/run/run_benchmark.py",
                "codeChunk": "def run_benchmark():\n    \"\"\"Run the benchmark.\"\"\"\n    print(\"Running benchmark for Code Index Tool\")\n    print(\"=================================\")\n    \n    if os.path.exists(\"benchmark.py\"):\n        print(\"Starting benchmark...\")\n        result = subprocess.run(['python', 'benchmark.py'])\n        if result.returncode == 0:\n            print(\"\u2713 Benchmark completed successfully\")\n            return True\n        else:\n            print(\"\u2717 Benchmark failed\")\n            return False\n    else:\n        print(\"\u2717 benchmark.py not found\")\n        return False\n\n\ndef",
                "startLine": 10,
                "endLine": 26,
                "type": "function_definition"
              }
            }
          ]
        },
        {
          "test_type": "basic",
          "query": "let",
          "min_score": 0.1,
          "max_results": 10,
          "status": "success",
          "results_count": 10,
          "valid_results_count": 10,
          "response_time": 49.53765869140625,
          "timestamp": "2025-08-24T17:41:59.854125",
          "results_sample": [
            {
              "id": "b62d7806-cd56-50c3-8343-fd951a77359d",
              "score": 0.42484888,
              "payload": {
                "filePath": "scripts/run/run_env_check.py",
                "codeChunk": "def run_env_verification():\n    \"\"\"Run the environment verification.\"\"\"\n    print(\"Running environment verification for Code Index Tool\")\n    print(\"==============================================\")\n    \n    if os.path.exists(\"verify_env.py\"):\n        print(\"Starting environment verification...\")\n        result = subprocess.run(['python', 'verify_env.py'])\n        if result.returncode == 0:\n            print(\"\u2713 Environment verification completed successfully\")\n            return True\n        else:\n            print(\"\u2717 Environment verification failed\")\n            return False\n    else:\n        print(\"\u2717 verify_env.py not found\")\n        return False\n\n\ndef",
                "startLine": 10,
                "endLine": 26,
                "type": "function_definition"
              }
            },
            {
              "id": "bebb0a11-3a42-593a-a198-c7d79341ea93",
              "score": 0.42293596,
              "payload": {
                "filePath": "kanban_api_config.json",
                "codeChunk": "\"ollama_model\": \"dengcao/Qwen3-Embedding-0.6B:F16\"",
                "startLine": 4,
                "endLine": 4,
                "type": "pair"
              }
            },
            {
              "id": "53cbb6db-63df-5702-9749-47821640e26d",
              "score": 0.42293596,
              "payload": {
                "filePath": "search_with_original_model.json",
                "codeChunk": "\"ollama_model\": \"dengcao/Qwen3-Embedding-0.6B:F16\"",
                "startLine": 4,
                "endLine": 4,
                "type": "pair"
              }
            }
          ]
        },
        {
          "test_type": "basic",
          "query": "const",
          "min_score": 0.1,
          "max_results": 10,
          "status": "success",
          "results_count": 10,
          "valid_results_count": 10,
          "response_time": 53.0850887298584,
          "timestamp": "2025-08-24T17:41:59.907237",
          "results_sample": [
            {
              "id": "b62d7806-cd56-50c3-8343-fd951a77359d",
              "score": 0.43385476,
              "payload": {
                "filePath": "scripts/run/run_env_check.py",
                "codeChunk": "def run_env_verification():\n    \"\"\"Run the environment verification.\"\"\"\n    print(\"Running environment verification for Code Index Tool\")\n    print(\"==============================================\")\n    \n    if os.path.exists(\"verify_env.py\"):\n        print(\"Starting environment verification...\")\n        result = subprocess.run(['python', 'verify_env.py'])\n        if result.returncode == 0:\n            print(\"\u2713 Environment verification completed successfully\")\n            return True\n        else:\n            print(\"\u2717 Environment verification failed\")\n            return False\n    else:\n        print(\"\u2717 verify_env.py not found\")\n        return False\n\n\ndef",
                "startLine": 10,
                "endLine": 26,
                "type": "function_definition"
              }
            },
            {
              "id": "8168407b-c422-5f6f-b7bf-e41c58fac0fb",
              "score": 0.42623204,
              "payload": {
                "filePath": "code_index.json",
                "codeChunk": "\"ollama_model\": \"dengcao/Qwen3-Embedding-0.6B:F16\"",
                "startLine": 4,
                "endLine": 4,
                "type": "pair"
              }
            },
            {
              "id": "bebb0a11-3a42-593a-a198-c7d79341ea93",
              "score": 0.42623204,
              "payload": {
                "filePath": "kanban_api_config.json",
                "codeChunk": "\"ollama_model\": \"dengcao/Qwen3-Embedding-0.6B:F16\"",
                "startLine": 4,
                "endLine": 4,
                "type": "pair"
              }
            }
          ]
        }
      ],
      "semantic_queries": [
        {
          "test_type": "semantic",
          "query": "authentication",
          "min_score": 0.1,
          "max_results": 10,
          "status": "success",
          "results_count": 10,
          "valid_results_count": 10,
          "response_time": 53.07340621948242,
          "timestamp": "2025-08-24T17:41:59.960366",
          "results_sample": [
            {
              "id": "53cbb6db-63df-5702-9749-47821640e26d",
              "score": 0.4372626,
              "payload": {
                "filePath": "search_with_original_model.json",
                "codeChunk": "\"ollama_model\": \"dengcao/Qwen3-Embedding-0.6B:F16\"",
                "startLine": 4,
                "endLine": 4,
                "type": "pair"
              }
            },
            {
              "id": "6321a5d0-2edc-51bc-8d83-58f3565d3348",
              "score": 0.4372626,
              "payload": {
                "filePath": "batch_config.json",
                "codeChunk": "\"ollama_model\": \"dengcao/Qwen3-Embedding-0.6B:F16\"",
                "startLine": 3,
                "endLine": 3,
                "type": "pair"
              }
            },
            {
              "id": "bebb0a11-3a42-593a-a198-c7d79341ea93",
              "score": 0.4372626,
              "payload": {
                "filePath": "kanban_api_config.json",
                "codeChunk": "\"ollama_model\": \"dengcao/Qwen3-Embedding-0.6B:F16\"",
                "startLine": 4,
                "endLine": 4,
                "type": "pair"
              }
            }
          ]
        },
        {
          "test_type": "semantic",
          "query": "database",
          "min_score": 0.1,
          "max_results": 10,
          "status": "success",
          "results_count": 10,
          "valid_results_count": 10,
          "response_time": 55.320024490356445,
          "timestamp": "2025-08-24T17:42:00.015712",
          "results_sample": [
            {
              "id": "53cbb6db-63df-5702-9749-47821640e26d",
              "score": 0.4058734,
              "payload": {
                "filePath": "search_with_original_model.json",
                "codeChunk": "\"ollama_model\": \"dengcao/Qwen3-Embedding-0.6B:F16\"",
                "startLine": 4,
                "endLine": 4,
                "type": "pair"
              }
            },
            {
              "id": "8168407b-c422-5f6f-b7bf-e41c58fac0fb",
              "score": 0.4058734,
              "payload": {
                "filePath": "code_index.json",
                "codeChunk": "\"ollama_model\": \"dengcao/Qwen3-Embedding-0.6B:F16\"",
                "startLine": 4,
                "endLine": 4,
                "type": "pair"
              }
            },
            {
              "id": "6321a5d0-2edc-51bc-8d83-58f3565d3348",
              "score": 0.4058734,
              "payload": {
                "filePath": "batch_config.json",
                "codeChunk": "\"ollama_model\": \"dengcao/Qwen3-Embedding-0.6B:F16\"",
                "startLine": 3,
                "endLine": 3,
                "type": "pair"
              }
            }
          ]
        },
        {
          "test_type": "semantic",
          "query": "API endpoint",
          "min_score": 0.1,
          "max_results": 10,
          "status": "success",
          "results_count": 10,
          "valid_results_count": 10,
          "response_time": 62.53528594970703,
          "timestamp": "2025-08-24T17:42:00.078279",
          "results_sample": [
            {
              "id": "3d5e024e-f3d5-5dd8-b9ba-5f084b8fd623",
              "score": 0.5324472,
              "payload": {
                "filePath": "kanban_api_config.json",
                "codeChunk": "\"workspace_path\": \"/home/james/kanban_frontend/kanban_api\"",
                "startLine": 2,
                "endLine": 2,
                "type": "pair"
              }
            },
            {
              "id": "5bfe288a-034f-5f36-af6a-ad132118bb36",
              "score": 0.49194467,
              "payload": {
                "filePath": "docs/code_index_plan.md",
                "codeChunk": "# Standalone Code Index Tool Implementation Plan\n\n## Overview\nCreate a standalone Python tool that can index code repositories using Ollama for embeddings and Qdrant for vector storage, based on the kilocode code-index functionality.\n\n## Core Components\n\n### 1. File Scanning and Filtering\n- **DirectoryScanner**: Recursively scan directories for code files\n- **FileFilter**: Filter files by supported extensions and ignore patterns\n- **Supported Extensions**: js, jsx, ts, tsx, py, rs, go, c, cpp, java, php, rb, etc.\n- **Ignore Handling**: Respect .gitignore and custom ignore patterns\n\n### 2. Code Parsing and Chunking\n- **CodeParser**: Parse code files into meaningful blocks\n- **TreeSitter Integration**: Use tree-sitter for language-aware parsing\n- **Fallback Chunking**: Line-based chunking for unsupported languages\n- **Chunking Logic**: Split large files into manageable chunks\n\n### 3. Embedding Generation\n- **OllamaEmbedder**: Interface with Ollama API for embeddings\n- **Model Support**: Support for various Ollama embedding models\n- **Batching**: Efficient batching of texts for embedding generation\n- **Error Handling**: Robust error handling for API calls",
                "startLine": 1,
                "endLine": 24,
                "type": "chunk"
              }
            },
            {
              "id": "078ada20-1da1-5ffc-bac3-61c41b97604e",
              "score": 0.44424564,
              "payload": {
                "filePath": "test_qdrant_direct.py",
                "codeChunk": "                max_results=5\n            )\n            \n            print(f\"Vector store search found {len(results)} results:\")\n            for i, result in enumerate(results):\n                payload = result.get(\"payload\", {})\n                file_path = payload.get(\"filePath\", \"Unknown\")\n                score = result.get(\"score\", 0)\n                print(f\"{i+1}. {file_path} (score: {score:.3f})\")\n                \n        except Exception as e:\n            print(f\"Vector store search error: {e}\")\n            import traceback\n            traceback.print_exc()\n            \n    except Exception as e:\n        print(f\"Error: {e}\")\n        import traceback\n        traceback.print_exc()\n\nif __name__ == \"__main__\":\n    test_qdrant_direct()",
                "startLine": 67,
                "endLine": 88,
                "type": "chunk"
              }
            }
          ]
        },
        {
          "test_type": "semantic",
          "query": "configuration",
          "min_score": 0.1,
          "max_results": 10,
          "status": "success",
          "results_count": 10,
          "valid_results_count": 10,
          "response_time": 56.92911148071289,
          "timestamp": "2025-08-24T17:42:00.135240",
          "results_sample": [
            {
              "id": "53cbb6db-63df-5702-9749-47821640e26d",
              "score": 0.44000408,
              "payload": {
                "filePath": "search_with_original_model.json",
                "codeChunk": "\"ollama_model\": \"dengcao/Qwen3-Embedding-0.6B:F16\"",
                "startLine": 4,
                "endLine": 4,
                "type": "pair"
              }
            },
            {
              "id": "6321a5d0-2edc-51bc-8d83-58f3565d3348",
              "score": 0.44000408,
              "payload": {
                "filePath": "batch_config.json",
                "codeChunk": "\"ollama_model\": \"dengcao/Qwen3-Embedding-0.6B:F16\"",
                "startLine": 3,
                "endLine": 3,
                "type": "pair"
              }
            },
            {
              "id": "bebb0a11-3a42-593a-a198-c7d79341ea93",
              "score": 0.44000408,
              "payload": {
                "filePath": "kanban_api_config.json",
                "codeChunk": "\"ollama_model\": \"dengcao/Qwen3-Embedding-0.6B:F16\"",
                "startLine": 4,
                "endLine": 4,
                "type": "pair"
              }
            }
          ]
        },
        {
          "test_type": "semantic",
          "query": "error handling",
          "min_score": 0.1,
          "max_results": 10,
          "status": "success",
          "results_count": 10,
          "valid_results_count": 10,
          "response_time": 55.043697357177734,
          "timestamp": "2025-08-24T17:42:00.190311",
          "results_sample": [
            {
              "id": "d3f2fd2d-730a-5ddd-a067-62bcf98955b7",
              "score": 0.6477706,
              "payload": {
                "filePath": "docs/code_index_plan.md",
                "codeChunk": "\u2502   \u251c\u2500\u2500 parser.py           # Code parsing\n\u2502   \u251c\u2500\u2500 embedder.py         # Ollama embedder\n\u2502   \u251c\u2500\u2500 vector_store.py     # Qdrant client\n\u2502   \u251c\u2500\u2500 cache.py            # Cache management\n\u2502   \u251c\u2500\u2500 config.py           # Configuration\n\u2502   \u2514\u2500\u2500 utils.py            # Utility functions\n\u251c\u2500\u2500 tests/\n\u251c\u2500\u2500 requirements.txt\n\u251c\u2500\u2500 README.md\n\u2514\u2500\u2500 setup.py\n```\n\n## Dependencies\n- `qdrant-client`: Qdrant Python client\n- `requests`: HTTP requests for Ollama API\n- `tree-sitter`: Code parsing\n- `tree-sitter-languages`: Language grammars\n- `click`: CLI framework\n- `tqdm`: Progress bars\n\n## Key Features\n- Standalone operation without VS Code\n- Support for multiple embedding models\n- Efficient file change detection\n- Configurable Qdrant and Ollama endpoints\n- Progress tracking and error reporting",
                "startLine": 63,
                "endLine": 88,
                "type": "chunk"
              }
            },
            {
              "id": "6e3d3e72-f80a-50ba-a0fd-c7f60753a444",
              "score": 0.5411918,
              "payload": {
                "filePath": "src/code_index/gitignore_manager.py",
                "codeChunk": "def _cache_template(self, template_name: str, content: str) -> None:\n        \"\"\"Cache template content.\"\"\"\n        cache_file = os.path.join(self.cache_dir, f\"{template_name}.gitignore\")\n        try:\n            with open(cache_file, 'w', encoding='utf-8') as f:\n                f.write(content)\n        except:\n            pass  # Silently fail on cache write errors",
                "startLine": 107,
                "endLine": 114,
                "type": "function_definition"
              }
            },
            {
              "id": "812431ad-148c-53f6-b464-06614ba0a364",
              "score": 0.53703344,
              "payload": {
                "filePath": "docs/enhancement_summary.md",
                "codeChunk": "- **Collection Management**: Eliminates duplicate indexing efforts\n\n### Resource Usage Optimization\n- **Memory Management**: Automatic collection pruning reduces storage needs\n- **Caching**: Parser and pattern caching improves repeated operations\n- **Parallel Processing**: Configurable parallelization for faster indexing\n\n### Storage Efficiency\n- **Single Collection Per Workspace**: Eliminates duplicate storage\n- **Smart Payload Storage**: Only necessary metadata stored\n- **Efficient Indexing**: Tree-sitter queries instead of naive AST traversal\n\n## Testing and Validation\n\n### Compatibility Tests\n- **KiloCode Recognition**: Verified that KiloCode recognizes our collections\n- **Payload Validation**: Confirmed matching field names and structure\n- **Search Integration**: Tested that KiloCode can search our indexed content\n\n### Performance Tests\n- **Indexing Speed**: Measured improvements in indexing time\n- **Search Quality**: Validated improved search result relevance\n- **Resource Usage**: Monitored memory and CPU usage during operations\n\n### Integration Tests\n- **End-to-End Workflow**: Verified complete indexing and search workflow\n- **Error Handling**: Tested graceful degradation and fallback mechanisms",
                "startLine": 160,
                "endLine": 186,
                "type": "chunk"
              }
            }
          ]
        },
        {
          "test_type": "semantic",
          "query": "logging",
          "min_score": 0.1,
          "max_results": 10,
          "status": "success",
          "results_count": 10,
          "valid_results_count": 10,
          "response_time": 56.12683296203613,
          "timestamp": "2025-08-24T17:42:00.246470",
          "results_sample": [
            {
              "id": "6321a5d0-2edc-51bc-8d83-58f3565d3348",
              "score": 0.44011003,
              "payload": {
                "filePath": "batch_config.json",
                "codeChunk": "\"ollama_model\": \"dengcao/Qwen3-Embedding-0.6B:F16\"",
                "startLine": 3,
                "endLine": 3,
                "type": "pair"
              }
            },
            {
              "id": "53cbb6db-63df-5702-9749-47821640e26d",
              "score": 0.44011003,
              "payload": {
                "filePath": "search_with_original_model.json",
                "codeChunk": "\"ollama_model\": \"dengcao/Qwen3-Embedding-0.6B:F16\"",
                "startLine": 4,
                "endLine": 4,
                "type": "pair"
              }
            },
            {
              "id": "8168407b-c422-5f6f-b7bf-e41c58fac0fb",
              "score": 0.44011003,
              "payload": {
                "filePath": "code_index.json",
                "codeChunk": "\"ollama_model\": \"dengcao/Qwen3-Embedding-0.6B:F16\"",
                "startLine": 4,
                "endLine": 4,
                "type": "pair"
              }
            }
          ]
        },
        {
          "test_type": "semantic",
          "query": "file operations",
          "min_score": 0.1,
          "max_results": 10,
          "status": "success",
          "results_count": 10,
          "valid_results_count": 10,
          "response_time": 62.73055076599121,
          "timestamp": "2025-08-24T17:42:00.309229",
          "results_sample": [
            {
              "id": "6e3d3e72-f80a-50ba-a0fd-c7f60753a444",
              "score": 0.4880588,
              "payload": {
                "filePath": "src/code_index/gitignore_manager.py",
                "codeChunk": "def _cache_template(self, template_name: str, content: str) -> None:\n        \"\"\"Cache template content.\"\"\"\n        cache_file = os.path.join(self.cache_dir, f\"{template_name}.gitignore\")\n        try:\n            with open(cache_file, 'w', encoding='utf-8') as f:\n                f.write(content)\n        except:\n            pass  # Silently fail on cache write errors",
                "startLine": 107,
                "endLine": 114,
                "type": "function_definition"
              }
            },
            {
              "id": "377ce442-978b-5f07-9d29-104408603061",
              "score": 0.47955745,
              "payload": {
                "filePath": "tests/test_basic.py",
                "codeChunk": "\"\"\"\nTest module for the code index tool.\n\"\"\"\nimport os\nimport tempfile\nimport pytest\nfrom code_index.config import Config\nfrom code_index.utils import get_file_hash, is_binary_file, is_supported_file\nfrom code_index.cache import CacheManager\n\n\ndef test_config():\n    \"\"\"Test configuration management.\"\"\"\n    config = Config()\n    assert config.ollama_base_url == \"http://localhost:11434\"\n    assert config.ollama_model == \"nomic-embed-text:latest\"\n    assert config.qdrant_url == \"http://localhost:6333\"\n    assert isinstance(config.extensions, list)\n    assert \".py\" in config.extensions\n\n\ndef test_file_hash():\n    \"\"\"Test file hash calculation.\"\"\"\n    # Create a temporary file\n    with tempfile.NamedTemporaryFile(mode=\"w\", delete=False) as f:\n        f.write(\"test content\")\n        temp_file = f.name\n    \n    try:\n        # Calculate hash\n        file_hash = get_file_hash(temp_file)\n        assert isinstance(file_hash, str)\n        assert len(file_hash) == 64  # SHA256 hash length\n    finally:\n        # Clean up\n        os.unlink(temp_file)\n\n\ndef test_binary_file_detection():\n    \"\"\"Test binary file detection.\"\"\"\n    # Create a text file",
                "startLine": 1,
                "endLine": 41,
                "type": "chunk"
              }
            },
            {
              "id": "56362a09-ea76-5b54-ae8c-2ade840538c1",
              "score": 0.46333742,
              "payload": {
                "filePath": "code_index_plan.txt",
                "codeChunk": "  configuration.Implementation Steps:1. Create FILE_TYPE_WEIGHTS configuration\n   2. Add content-based relevance scoring\n   3. Implement semantic keyword boosting\n\n  PHASE 4: SEARCH TERM GUIDANCE & ENHANCEMENT\n\n  Task7: Intelligent Query EnhancementFiles to create: src/code_index/search_enhancer.py\n  Description: Enhance search queries with synonyms and related terms.\n\n  Implementation Steps:1. Create QueryEnhancer class\n   2. Implement synonym mapping for common technical terms\n   3. Add query expansion logic\n\n  Task 8: Interactive Query Builder\n  Files to modify: src/code_index/cli.py\n  Description: Add interactive features for better search experience.\n\n  Implementation Steps:1. Add --interactive mode for guided search\n   2. Implement --examples command for query examples\n   3. Add --suggest feature for query suggestions\n\n  PHASE 5: PERFORMANCE OPTIMIZATIONS\n\n  Task 9: Configurable ParallelizationFiles to modify: src/code_index/config.py, \n  src/code_index/cli.py\n  Description: Add parallel processing capabilities for better performance.Implementation Steps:1.\n  Add parallelization settings to configuration\n   2. Implement multi-threaded file processing",
                "startLine": 51,
                "endLine": 78,
                "type": "chunk"
              }
            }
          ]
        },
        {
          "test_type": "semantic",
          "query": "network request",
          "min_score": 0.1,
          "max_results": 10,
          "status": "success",
          "results_count": 10,
          "valid_results_count": 10,
          "response_time": 63.80271911621094,
          "timestamp": "2025-08-24T17:42:00.373067",
          "results_sample": [
            {
              "id": "3d5e024e-f3d5-5dd8-b9ba-5f084b8fd623",
              "score": 0.46648365,
              "payload": {
                "filePath": "kanban_api_config.json",
                "codeChunk": "\"workspace_path\": \"/home/james/kanban_frontend/kanban_api\"",
                "startLine": 2,
                "endLine": 2,
                "type": "pair"
              }
            },
            {
              "id": "5bfe288a-034f-5f36-af6a-ad132118bb36",
              "score": 0.4488845,
              "payload": {
                "filePath": "docs/code_index_plan.md",
                "codeChunk": "# Standalone Code Index Tool Implementation Plan\n\n## Overview\nCreate a standalone Python tool that can index code repositories using Ollama for embeddings and Qdrant for vector storage, based on the kilocode code-index functionality.\n\n## Core Components\n\n### 1. File Scanning and Filtering\n- **DirectoryScanner**: Recursively scan directories for code files\n- **FileFilter**: Filter files by supported extensions and ignore patterns\n- **Supported Extensions**: js, jsx, ts, tsx, py, rs, go, c, cpp, java, php, rb, etc.\n- **Ignore Handling**: Respect .gitignore and custom ignore patterns\n\n### 2. Code Parsing and Chunking\n- **CodeParser**: Parse code files into meaningful blocks\n- **TreeSitter Integration**: Use tree-sitter for language-aware parsing\n- **Fallback Chunking**: Line-based chunking for unsupported languages\n- **Chunking Logic**: Split large files into manageable chunks\n\n### 3. Embedding Generation\n- **OllamaEmbedder**: Interface with Ollama API for embeddings\n- **Model Support**: Support for various Ollama embedding models\n- **Batching**: Efficient batching of texts for embedding generation\n- **Error Handling**: Robust error handling for API calls",
                "startLine": 1,
                "endLine": 24,
                "type": "chunk"
              }
            },
            {
              "id": "8168407b-c422-5f6f-b7bf-e41c58fac0fb",
              "score": 0.4125384,
              "payload": {
                "filePath": "code_index.json",
                "codeChunk": "\"ollama_model\": \"dengcao/Qwen3-Embedding-0.6B:F16\"",
                "startLine": 4,
                "endLine": 4,
                "type": "pair"
              }
            }
          ]
        },
        {
          "test_type": "semantic",
          "query": "user interface",
          "min_score": 0.1,
          "max_results": 10,
          "status": "success",
          "results_count": 10,
          "valid_results_count": 10,
          "response_time": 57.92689323425293,
          "timestamp": "2025-08-24T17:42:00.431019",
          "results_sample": [
            {
              "id": "32c4bd25-ea5c-5ca7-9b2f-6beef43cc2ac",
              "score": 0.52221155,
              "payload": {
                "filePath": "code_index_plan.txt",
                "codeChunk": "  monitoring.\n\n  Implementation Steps:1. Add health command for system status\n   2. Implement service connectivity checks3. Add configuration validation\n\n  Implementation Priority\n\n  High Priority (Next Sprint):\n   1. Task 1: Enhanced Collection Metadata Storage2. Task 2: Collections List Command\n   3. Task 6: File Type Weighting System\n   4. Task 9: Configurable Parallelization### Medium Priority (Following Sprint):\n   1. Task 3: Multi-Layer Ignore Pattern System\n   2. Task 7: Intelligent Query Enhancement\n   3. Task 11: Automatic Collection Pruning\n   4. Task 12: Graceful Degradation\n\n  Low Priority (Future Enhancements):\n   1. Task 4: .codeignore File Support\n   2. Task 5: CLI Ignore Configuration Options\n   3. Task 8: Interactive Query Builder\n   4. Task 10: Progress Reporting5. Task 13: Health Check Commands\n\n  Testing Strategy\n\n  Unit Tests:\n   - Test ignore pattern matching logic\n   - Verify file type weighting calculations- Test query enhancement functionality\n\n  Integration Tests:\n   - End-to-end collection management\n   - Performance testing with large codebases\n   - Error handling scenarios\n\n  User Acceptance Tests:- Interactive command workflows",
                "startLine": 111,
                "endLine": 144,
                "type": "chunk"
              }
            },
            {
              "id": "d3f2fd2d-730a-5ddd-a067-62bcf98955b7",
              "score": 0.41815105,
              "payload": {
                "filePath": "docs/code_index_plan.md",
                "codeChunk": "\u2502   \u251c\u2500\u2500 parser.py           # Code parsing\n\u2502   \u251c\u2500\u2500 embedder.py         # Ollama embedder\n\u2502   \u251c\u2500\u2500 vector_store.py     # Qdrant client\n\u2502   \u251c\u2500\u2500 cache.py            # Cache management\n\u2502   \u251c\u2500\u2500 config.py           # Configuration\n\u2502   \u2514\u2500\u2500 utils.py            # Utility functions\n\u251c\u2500\u2500 tests/\n\u251c\u2500\u2500 requirements.txt\n\u251c\u2500\u2500 README.md\n\u2514\u2500\u2500 setup.py\n```\n\n## Dependencies\n- `qdrant-client`: Qdrant Python client\n- `requests`: HTTP requests for Ollama API\n- `tree-sitter`: Code parsing\n- `tree-sitter-languages`: Language grammars\n- `click`: CLI framework\n- `tqdm`: Progress bars\n\n## Key Features\n- Standalone operation without VS Code\n- Support for multiple embedding models\n- Efficient file change detection\n- Configurable Qdrant and Ollama endpoints\n- Progress tracking and error reporting",
                "startLine": 63,
                "endLine": 88,
                "type": "chunk"
              }
            },
            {
              "id": "d165be03-b803-5d63-afd2-b110be916991",
              "score": 0.41725183,
              "payload": {
                "filePath": "docs/indexing_status_tracking.md",
                "codeChunk": "\n### Phase 1: Core State Management\n- [ ] Implement IndexingStateManager\n- [ ] Add state transition logic\n- [ ] Implement progress reporting\n\n### Phase 2: Orchestrator Integration\n- [ ] Implement IndexingOrchestrator\n- [ ] Integrate with existing components\n- [ ] Add progress callback support\n\n### Phase 3: Scanner Enhancement\n- [ ] Modify scanner to report progress\n- [ ] Add file parsing progress callbacks\n- [ ] Add block indexing progress callbacks\n\n### Phase 4: CLI Integration\n- [ ] Add progress display options\n- [ ] Implement progress output formatting\n- [ ] Add real-time status commands\n\n## Benefits\n\n1. **Real-time Feedback**: Users can see exactly what's happening during indexing\n2. **Progress Tracking**: Clear indication of how much work remains\n3. **Error Handling**: Better error reporting and recovery\n4. **User Experience**: Improved CLI experience with status updates\n5. **Debugging**: Easier to diagnose issues with detailed progress information\n\n## Future Enhancements\n\n1. **ETA Calculation**: Estimate completion time based on progress rate\n2. **Pause/Resume**: Allow interrupting and resuming indexing\n3. **Web UI**: Progress display in a web interface",
                "startLine": 305,
                "endLine": 338,
                "type": "chunk"
              }
            }
          ]
        },
        {
          "test_type": "semantic",
          "query": "data validation",
          "min_score": 0.1,
          "max_results": 10,
          "status": "success",
          "results_count": 10,
          "valid_results_count": 10,
          "response_time": 53.414344787597656,
          "timestamp": "2025-08-24T17:42:00.484458",
          "results_sample": [
            {
              "id": "fe874baf-7eb0-5ec4-8c63-29d4559115b0",
              "score": 0.5521949,
              "payload": {
                "filePath": "docs/code_index_checklist.md",
                "codeChunk": "# Implementation Checklist\n\n## 1. Project Setup\n1. [ ] Create project directory structure\n2. [ ] Set up virtual environment\n3. [ ] Create requirements.txt with dependencies\n4. [ ] Initialize Git repository\n5. [ ] Create basic README.md\n\n## 2. Core Infrastructure\n1. [ ] Implement configuration management (config.py)\n2. [ ] Implement utility functions (utils.py)\n3. [ ] Set up logging system\n4. [ ] Create base classes and interfaces\n\n## 3. File Scanning and Filtering\n1. [ ] Implement directory scanner (scanner.py)\n2. [ ] Implement file filtering logic\n3. [ ] Add support for ignore patterns (.gitignore parsing)\n4. [ ] Implement file extension filtering\n\n## 4. Code Parsing and Chunking\n1. [ ] Set up tree-sitter integration\n2. [ ] Implement language-specific parsers\n3. [ ] Create code block extraction logic\n4. [ ] Implement fallback chunking for large files\n5. [ ] Add support for multiple programming languages\n\n## 5. Ollama Embedding Generation\n1. [ ] Implement Ollama client (embedder.py)\n2. [ ] Add support for different embedding models\n3. [ ] Implement batching for efficiency\n4. [ ] Add error handling and retries\n5. [ ] Implement model validation",
                "startLine": 1,
                "endLine": 34,
                "type": "chunk"
              }
            },
            {
              "id": "de39cd18-50c0-5302-8bf4-b170cea4c8f7",
              "score": 0.42616206,
              "payload": {
                "filePath": "scripts/testing/test_models.py",
                "codeChunk": "#!/usr/bin/env python3\n\"\"\"\nScript to demonstrate using different Ollama models with the code index tool.\n\"\"\"\nimport json\nimport os\nfrom code_index.src.config import Config\nfrom code_index.src.embedder import OllamaEmbedder\n\n\ndef test_ollama_models():\n    \"\"\"Test different Ollama models.\"\"\"\n    print(\"Testing Ollama Models\")\n    print(\"=====================\")\n    \n    # Common embedding models available in Ollama\n    models_to_test = [\n        \"nomic-embed-text:latest\",\n        \"mxbai-embed-large:latest\",\n        \"nomic-embed-code:7b-Q4_K_M\",  # If you have this one\n    ]\n    \n    # Test each model\n    for model_name in models_to_test:\n        print(f\"\\nTesting model: {model_name}\")\n        \n        # Create configuration with this model\n        config = Config()\n        config.ollama_model = model_name\n        \n        # Create embedder\n        embedder = OllamaEmbedder(config)\n        \n        # Validate configuration\n        try:\n            result = embedder.validate_configuration()\n            if result[\"valid\"]:\n                print(f\"  \u2713 Model is available and working\")\n                \n                # Test embedding generation",
                "startLine": 1,
                "endLine": 40,
                "type": "chunk"
              }
            },
            {
              "id": "1189d5e8-f3c9-53f2-9cf0-89dfcd416ea1",
              "score": 0.40551394,
              "payload": {
                "filePath": "test_simple_search.py",
                "codeChunk": "            print(f\"Error searching: {e}\")\n\nif __name__ == \"__main__\":\n    test_simple_search()",
                "startLine": 67,
                "endLine": 70,
                "type": "chunk"
              }
            }
          ]
        }
      ],
      "score_thresholds": [
        {
          "test_type": "score_threshold_0.1",
          "query": "function",
          "min_score": 0.1,
          "max_results": 20,
          "status": "success",
          "results_count": 20,
          "valid_results_count": 20,
          "response_time": 57.645320892333984,
          "timestamp": "2025-08-24T17:42:00.542162",
          "results_sample": [
            {
              "id": "e291927d-397c-5da3-8234-6494748cb314",
              "score": 0.3995579,
              "payload": {
                "filePath": "docs/README.md",
                "codeChunk": "\n2. **Code Parsing**: Files are parsed into meaningful code blocks. For now, a simple line-based chunking approach is used, but this could be enhanced with tree-sitter parsing in the future.\n\n3. **Embedding Generation**: Ollama is used to generate vector embeddings for each code block.\n\n4. **Vector Storage**: Embeddings are stored in Qdrant with metadata about the file path, line numbers, and content.\n\n5. **Caching**: File hashes are cached to avoid reprocessing unchanged files.\n\n6. **Search**: Semantic search is performed by generating an embedding for the query and finding similar vectors in Qdrant.\n\n## Example Workflow\n\n```bash\n# Index your codebase\ncode-index index --workspace /path/to/your/project\n\n# Search for specific functionality\ncode-index search \"database connection function\"\n\n# Search with custom parameters\ncode-index search \"API endpoint\" --min-score 0.5 --max-results 20\n```\n\n## Development\n\nFor development and testing scripts, see the `scripts/` directory and documentation in `docs/development/`.\n\n## License\n\nMIT\n## Advanced Features\n\n### Config-first Embedding Length\n- You must set a dimension that matches your embedding model:",
                "startLine": 129,
                "endLine": 163,
                "type": "chunk"
              }
            },
            {
              "id": "b62d7806-cd56-50c3-8343-fd951a77359d",
              "score": 0.3981247,
              "payload": {
                "filePath": "scripts/run/run_env_check.py",
                "codeChunk": "def run_env_verification():\n    \"\"\"Run the environment verification.\"\"\"\n    print(\"Running environment verification for Code Index Tool\")\n    print(\"==============================================\")\n    \n    if os.path.exists(\"verify_env.py\"):\n        print(\"Starting environment verification...\")\n        result = subprocess.run(['python', 'verify_env.py'])\n        if result.returncode == 0:\n            print(\"\u2713 Environment verification completed successfully\")\n            return True\n        else:\n            print(\"\u2717 Environment verification failed\")\n            return False\n    else:\n        print(\"\u2717 verify_env.py not found\")\n        return False\n\n\ndef",
                "startLine": 10,
                "endLine": 26,
                "type": "function_definition"
              }
            },
            {
              "id": "94e356aa-66b6-53e6-a388-8308d091785e",
              "score": 0.37110496,
              "payload": {
                "filePath": "scripts/run/run_benchmark.py",
                "codeChunk": "def run_benchmark():\n    \"\"\"Run the benchmark.\"\"\"\n    print(\"Running benchmark for Code Index Tool\")\n    print(\"=================================\")\n    \n    if os.path.exists(\"benchmark.py\"):\n        print(\"Starting benchmark...\")\n        result = subprocess.run(['python', 'benchmark.py'])\n        if result.returncode == 0:\n            print(\"\u2713 Benchmark completed successfully\")\n            return True\n        else:\n            print(\"\u2717 Benchmark failed\")\n            return False\n    else:\n        print(\"\u2717 benchmark.py not found\")\n        return False\n\n\ndef",
                "startLine": 10,
                "endLine": 26,
                "type": "function_definition"
              }
            }
          ]
        },
        {
          "test_type": "score_threshold_0.3",
          "query": "function",
          "min_score": 0.3,
          "max_results": 20,
          "status": "success",
          "results_count": 18,
          "valid_results_count": 18,
          "response_time": 58.56800079345703,
          "timestamp": "2025-08-24T17:42:00.600763",
          "results_sample": [
            {
              "id": "e291927d-397c-5da3-8234-6494748cb314",
              "score": 0.3995579,
              "payload": {
                "filePath": "docs/README.md",
                "codeChunk": "\n2. **Code Parsing**: Files are parsed into meaningful code blocks. For now, a simple line-based chunking approach is used, but this could be enhanced with tree-sitter parsing in the future.\n\n3. **Embedding Generation**: Ollama is used to generate vector embeddings for each code block.\n\n4. **Vector Storage**: Embeddings are stored in Qdrant with metadata about the file path, line numbers, and content.\n\n5. **Caching**: File hashes are cached to avoid reprocessing unchanged files.\n\n6. **Search**: Semantic search is performed by generating an embedding for the query and finding similar vectors in Qdrant.\n\n## Example Workflow\n\n```bash\n# Index your codebase\ncode-index index --workspace /path/to/your/project\n\n# Search for specific functionality\ncode-index search \"database connection function\"\n\n# Search with custom parameters\ncode-index search \"API endpoint\" --min-score 0.5 --max-results 20\n```\n\n## Development\n\nFor development and testing scripts, see the `scripts/` directory and documentation in `docs/development/`.\n\n## License\n\nMIT\n## Advanced Features\n\n### Config-first Embedding Length\n- You must set a dimension that matches your embedding model:",
                "startLine": 129,
                "endLine": 163,
                "type": "chunk"
              }
            },
            {
              "id": "b62d7806-cd56-50c3-8343-fd951a77359d",
              "score": 0.3981247,
              "payload": {
                "filePath": "scripts/run/run_env_check.py",
                "codeChunk": "def run_env_verification():\n    \"\"\"Run the environment verification.\"\"\"\n    print(\"Running environment verification for Code Index Tool\")\n    print(\"==============================================\")\n    \n    if os.path.exists(\"verify_env.py\"):\n        print(\"Starting environment verification...\")\n        result = subprocess.run(['python', 'verify_env.py'])\n        if result.returncode == 0:\n            print(\"\u2713 Environment verification completed successfully\")\n            return True\n        else:\n            print(\"\u2717 Environment verification failed\")\n            return False\n    else:\n        print(\"\u2717 verify_env.py not found\")\n        return False\n\n\ndef",
                "startLine": 10,
                "endLine": 26,
                "type": "function_definition"
              }
            },
            {
              "id": "94e356aa-66b6-53e6-a388-8308d091785e",
              "score": 0.37110496,
              "payload": {
                "filePath": "scripts/run/run_benchmark.py",
                "codeChunk": "def run_benchmark():\n    \"\"\"Run the benchmark.\"\"\"\n    print(\"Running benchmark for Code Index Tool\")\n    print(\"=================================\")\n    \n    if os.path.exists(\"benchmark.py\"):\n        print(\"Starting benchmark...\")\n        result = subprocess.run(['python', 'benchmark.py'])\n        if result.returncode == 0:\n            print(\"\u2713 Benchmark completed successfully\")\n            return True\n        else:\n            print(\"\u2717 Benchmark failed\")\n            return False\n    else:\n        print(\"\u2717 benchmark.py not found\")\n        return False\n\n\ndef",
                "startLine": 10,
                "endLine": 26,
                "type": "function_definition"
              }
            }
          ]
        },
        {
          "test_type": "score_threshold_0.5",
          "query": "function",
          "min_score": 0.5,
          "max_results": 20,
          "status": "success",
          "results_count": 0,
          "valid_results_count": 0,
          "response_time": 52.82402038574219,
          "timestamp": "2025-08-24T17:42:00.653616",
          "results_sample": []
        },
        {
          "test_type": "score_threshold_0.7",
          "query": "function",
          "min_score": 0.7,
          "max_results": 20,
          "status": "success",
          "results_count": 0,
          "valid_results_count": 0,
          "response_time": 53.16805839538574,
          "timestamp": "2025-08-24T17:42:00.706810",
          "results_sample": []
        },
        {
          "test_type": "score_threshold_0.9",
          "query": "function",
          "min_score": 0.9,
          "max_results": 20,
          "status": "success",
          "results_count": 0,
          "valid_results_count": 0,
          "response_time": 51.757097244262695,
          "timestamp": "2025-08-24T17:42:00.758592",
          "results_sample": []
        }
      ],
      "result_limits": [
        {
          "test_type": "result_limit_5",
          "query": "class",
          "min_score": 0.1,
          "max_results": 5,
          "status": "success",
          "results_count": 5,
          "valid_results_count": 5,
          "response_time": 53.247928619384766,
          "timestamp": "2025-08-24T17:42:00.811888",
          "results_sample": [
            {
              "id": "b62d7806-cd56-50c3-8343-fd951a77359d",
              "score": 0.3890106,
              "payload": {
                "filePath": "scripts/run/run_env_check.py",
                "codeChunk": "def run_env_verification():\n    \"\"\"Run the environment verification.\"\"\"\n    print(\"Running environment verification for Code Index Tool\")\n    print(\"==============================================\")\n    \n    if os.path.exists(\"verify_env.py\"):\n        print(\"Starting environment verification...\")\n        result = subprocess.run(['python', 'verify_env.py'])\n        if result.returncode == 0:\n            print(\"\u2713 Environment verification completed successfully\")\n            return True\n        else:\n            print(\"\u2717 Environment verification failed\")\n            return False\n    else:\n        print(\"\u2717 verify_env.py not found\")\n        return False\n\n\ndef",
                "startLine": 10,
                "endLine": 26,
                "type": "function_definition"
              }
            },
            {
              "id": "e291927d-397c-5da3-8234-6494748cb314",
              "score": 0.38753754,
              "payload": {
                "filePath": "docs/README.md",
                "codeChunk": "\n2. **Code Parsing**: Files are parsed into meaningful code blocks. For now, a simple line-based chunking approach is used, but this could be enhanced with tree-sitter parsing in the future.\n\n3. **Embedding Generation**: Ollama is used to generate vector embeddings for each code block.\n\n4. **Vector Storage**: Embeddings are stored in Qdrant with metadata about the file path, line numbers, and content.\n\n5. **Caching**: File hashes are cached to avoid reprocessing unchanged files.\n\n6. **Search**: Semantic search is performed by generating an embedding for the query and finding similar vectors in Qdrant.\n\n## Example Workflow\n\n```bash\n# Index your codebase\ncode-index index --workspace /path/to/your/project\n\n# Search for specific functionality\ncode-index search \"database connection function\"\n\n# Search with custom parameters\ncode-index search \"API endpoint\" --min-score 0.5 --max-results 20\n```\n\n## Development\n\nFor development and testing scripts, see the `scripts/` directory and documentation in `docs/development/`.\n\n## License\n\nMIT\n## Advanced Features\n\n### Config-first Embedding Length\n- You must set a dimension that matches your embedding model:",
                "startLine": 129,
                "endLine": 163,
                "type": "chunk"
              }
            },
            {
              "id": "53cbb6db-63df-5702-9749-47821640e26d",
              "score": 0.37641048,
              "payload": {
                "filePath": "search_with_original_model.json",
                "codeChunk": "\"ollama_model\": \"dengcao/Qwen3-Embedding-0.6B:F16\"",
                "startLine": 4,
                "endLine": 4,
                "type": "pair"
              }
            }
          ]
        },
        {
          "test_type": "result_limit_10",
          "query": "class",
          "min_score": 0.1,
          "max_results": 10,
          "status": "success",
          "results_count": 10,
          "valid_results_count": 10,
          "response_time": 56.592702865600586,
          "timestamp": "2025-08-24T17:42:00.868509",
          "results_sample": [
            {
              "id": "b62d7806-cd56-50c3-8343-fd951a77359d",
              "score": 0.3890106,
              "payload": {
                "filePath": "scripts/run/run_env_check.py",
                "codeChunk": "def run_env_verification():\n    \"\"\"Run the environment verification.\"\"\"\n    print(\"Running environment verification for Code Index Tool\")\n    print(\"==============================================\")\n    \n    if os.path.exists(\"verify_env.py\"):\n        print(\"Starting environment verification...\")\n        result = subprocess.run(['python', 'verify_env.py'])\n        if result.returncode == 0:\n            print(\"\u2713 Environment verification completed successfully\")\n            return True\n        else:\n            print(\"\u2717 Environment verification failed\")\n            return False\n    else:\n        print(\"\u2717 verify_env.py not found\")\n        return False\n\n\ndef",
                "startLine": 10,
                "endLine": 26,
                "type": "function_definition"
              }
            },
            {
              "id": "e291927d-397c-5da3-8234-6494748cb314",
              "score": 0.38753754,
              "payload": {
                "filePath": "docs/README.md",
                "codeChunk": "\n2. **Code Parsing**: Files are parsed into meaningful code blocks. For now, a simple line-based chunking approach is used, but this could be enhanced with tree-sitter parsing in the future.\n\n3. **Embedding Generation**: Ollama is used to generate vector embeddings for each code block.\n\n4. **Vector Storage**: Embeddings are stored in Qdrant with metadata about the file path, line numbers, and content.\n\n5. **Caching**: File hashes are cached to avoid reprocessing unchanged files.\n\n6. **Search**: Semantic search is performed by generating an embedding for the query and finding similar vectors in Qdrant.\n\n## Example Workflow\n\n```bash\n# Index your codebase\ncode-index index --workspace /path/to/your/project\n\n# Search for specific functionality\ncode-index search \"database connection function\"\n\n# Search with custom parameters\ncode-index search \"API endpoint\" --min-score 0.5 --max-results 20\n```\n\n## Development\n\nFor development and testing scripts, see the `scripts/` directory and documentation in `docs/development/`.\n\n## License\n\nMIT\n## Advanced Features\n\n### Config-first Embedding Length\n- You must set a dimension that matches your embedding model:",
                "startLine": 129,
                "endLine": 163,
                "type": "chunk"
              }
            },
            {
              "id": "bebb0a11-3a42-593a-a198-c7d79341ea93",
              "score": 0.37641048,
              "payload": {
                "filePath": "kanban_api_config.json",
                "codeChunk": "\"ollama_model\": \"dengcao/Qwen3-Embedding-0.6B:F16\"",
                "startLine": 4,
                "endLine": 4,
                "type": "pair"
              }
            }
          ]
        },
        {
          "test_type": "result_limit_20",
          "query": "class",
          "min_score": 0.1,
          "max_results": 20,
          "status": "success",
          "results_count": 20,
          "valid_results_count": 20,
          "response_time": 59.576988220214844,
          "timestamp": "2025-08-24T17:42:00.928130",
          "results_sample": [
            {
              "id": "b62d7806-cd56-50c3-8343-fd951a77359d",
              "score": 0.3890106,
              "payload": {
                "filePath": "scripts/run/run_env_check.py",
                "codeChunk": "def run_env_verification():\n    \"\"\"Run the environment verification.\"\"\"\n    print(\"Running environment verification for Code Index Tool\")\n    print(\"==============================================\")\n    \n    if os.path.exists(\"verify_env.py\"):\n        print(\"Starting environment verification...\")\n        result = subprocess.run(['python', 'verify_env.py'])\n        if result.returncode == 0:\n            print(\"\u2713 Environment verification completed successfully\")\n            return True\n        else:\n            print(\"\u2717 Environment verification failed\")\n            return False\n    else:\n        print(\"\u2717 verify_env.py not found\")\n        return False\n\n\ndef",
                "startLine": 10,
                "endLine": 26,
                "type": "function_definition"
              }
            },
            {
              "id": "e291927d-397c-5da3-8234-6494748cb314",
              "score": 0.38753754,
              "payload": {
                "filePath": "docs/README.md",
                "codeChunk": "\n2. **Code Parsing**: Files are parsed into meaningful code blocks. For now, a simple line-based chunking approach is used, but this could be enhanced with tree-sitter parsing in the future.\n\n3. **Embedding Generation**: Ollama is used to generate vector embeddings for each code block.\n\n4. **Vector Storage**: Embeddings are stored in Qdrant with metadata about the file path, line numbers, and content.\n\n5. **Caching**: File hashes are cached to avoid reprocessing unchanged files.\n\n6. **Search**: Semantic search is performed by generating an embedding for the query and finding similar vectors in Qdrant.\n\n## Example Workflow\n\n```bash\n# Index your codebase\ncode-index index --workspace /path/to/your/project\n\n# Search for specific functionality\ncode-index search \"database connection function\"\n\n# Search with custom parameters\ncode-index search \"API endpoint\" --min-score 0.5 --max-results 20\n```\n\n## Development\n\nFor development and testing scripts, see the `scripts/` directory and documentation in `docs/development/`.\n\n## License\n\nMIT\n## Advanced Features\n\n### Config-first Embedding Length\n- You must set a dimension that matches your embedding model:",
                "startLine": 129,
                "endLine": 163,
                "type": "chunk"
              }
            },
            {
              "id": "53cbb6db-63df-5702-9749-47821640e26d",
              "score": 0.37641048,
              "payload": {
                "filePath": "search_with_original_model.json",
                "codeChunk": "\"ollama_model\": \"dengcao/Qwen3-Embedding-0.6B:F16\"",
                "startLine": 4,
                "endLine": 4,
                "type": "pair"
              }
            }
          ]
        },
        {
          "test_type": "result_limit_50",
          "query": "class",
          "min_score": 0.1,
          "max_results": 50,
          "status": "success",
          "results_count": 50,
          "valid_results_count": 50,
          "response_time": 59.25273895263672,
          "timestamp": "2025-08-24T17:42:00.987438",
          "results_sample": [
            {
              "id": "b62d7806-cd56-50c3-8343-fd951a77359d",
              "score": 0.3890106,
              "payload": {
                "filePath": "scripts/run/run_env_check.py",
                "codeChunk": "def run_env_verification():\n    \"\"\"Run the environment verification.\"\"\"\n    print(\"Running environment verification for Code Index Tool\")\n    print(\"==============================================\")\n    \n    if os.path.exists(\"verify_env.py\"):\n        print(\"Starting environment verification...\")\n        result = subprocess.run(['python', 'verify_env.py'])\n        if result.returncode == 0:\n            print(\"\u2713 Environment verification completed successfully\")\n            return True\n        else:\n            print(\"\u2717 Environment verification failed\")\n            return False\n    else:\n        print(\"\u2717 verify_env.py not found\")\n        return False\n\n\ndef",
                "startLine": 10,
                "endLine": 26,
                "type": "function_definition"
              }
            },
            {
              "id": "e291927d-397c-5da3-8234-6494748cb314",
              "score": 0.38753754,
              "payload": {
                "filePath": "docs/README.md",
                "codeChunk": "\n2. **Code Parsing**: Files are parsed into meaningful code blocks. For now, a simple line-based chunking approach is used, but this could be enhanced with tree-sitter parsing in the future.\n\n3. **Embedding Generation**: Ollama is used to generate vector embeddings for each code block.\n\n4. **Vector Storage**: Embeddings are stored in Qdrant with metadata about the file path, line numbers, and content.\n\n5. **Caching**: File hashes are cached to avoid reprocessing unchanged files.\n\n6. **Search**: Semantic search is performed by generating an embedding for the query and finding similar vectors in Qdrant.\n\n## Example Workflow\n\n```bash\n# Index your codebase\ncode-index index --workspace /path/to/your/project\n\n# Search for specific functionality\ncode-index search \"database connection function\"\n\n# Search with custom parameters\ncode-index search \"API endpoint\" --min-score 0.5 --max-results 20\n```\n\n## Development\n\nFor development and testing scripts, see the `scripts/` directory and documentation in `docs/development/`.\n\n## License\n\nMIT\n## Advanced Features\n\n### Config-first Embedding Length\n- You must set a dimension that matches your embedding model:",
                "startLine": 129,
                "endLine": 163,
                "type": "chunk"
              }
            },
            {
              "id": "6321a5d0-2edc-51bc-8d83-58f3565d3348",
              "score": 0.37641048,
              "payload": {
                "filePath": "batch_config.json",
                "codeChunk": "\"ollama_model\": \"dengcao/Qwen3-Embedding-0.6B:F16\"",
                "startLine": 3,
                "endLine": 3,
                "type": "pair"
              }
            }
          ]
        },
        {
          "test_type": "result_limit_100",
          "query": "class",
          "min_score": 0.1,
          "max_results": 100,
          "status": "success",
          "results_count": 100,
          "valid_results_count": 100,
          "response_time": 53.76768112182617,
          "timestamp": "2025-08-24T17:42:01.041278",
          "results_sample": [
            {
              "id": "b62d7806-cd56-50c3-8343-fd951a77359d",
              "score": 0.3890106,
              "payload": {
                "filePath": "scripts/run/run_env_check.py",
                "codeChunk": "def run_env_verification():\n    \"\"\"Run the environment verification.\"\"\"\n    print(\"Running environment verification for Code Index Tool\")\n    print(\"==============================================\")\n    \n    if os.path.exists(\"verify_env.py\"):\n        print(\"Starting environment verification...\")\n        result = subprocess.run(['python', 'verify_env.py'])\n        if result.returncode == 0:\n            print(\"\u2713 Environment verification completed successfully\")\n            return True\n        else:\n            print(\"\u2717 Environment verification failed\")\n            return False\n    else:\n        print(\"\u2717 verify_env.py not found\")\n        return False\n\n\ndef",
                "startLine": 10,
                "endLine": 26,
                "type": "function_definition"
              }
            },
            {
              "id": "e291927d-397c-5da3-8234-6494748cb314",
              "score": 0.38753754,
              "payload": {
                "filePath": "docs/README.md",
                "codeChunk": "\n2. **Code Parsing**: Files are parsed into meaningful code blocks. For now, a simple line-based chunking approach is used, but this could be enhanced with tree-sitter parsing in the future.\n\n3. **Embedding Generation**: Ollama is used to generate vector embeddings for each code block.\n\n4. **Vector Storage**: Embeddings are stored in Qdrant with metadata about the file path, line numbers, and content.\n\n5. **Caching**: File hashes are cached to avoid reprocessing unchanged files.\n\n6. **Search**: Semantic search is performed by generating an embedding for the query and finding similar vectors in Qdrant.\n\n## Example Workflow\n\n```bash\n# Index your codebase\ncode-index index --workspace /path/to/your/project\n\n# Search for specific functionality\ncode-index search \"database connection function\"\n\n# Search with custom parameters\ncode-index search \"API endpoint\" --min-score 0.5 --max-results 20\n```\n\n## Development\n\nFor development and testing scripts, see the `scripts/` directory and documentation in `docs/development/`.\n\n## License\n\nMIT\n## Advanced Features\n\n### Config-first Embedding Length\n- You must set a dimension that matches your embedding model:",
                "startLine": 129,
                "endLine": 163,
                "type": "chunk"
              }
            },
            {
              "id": "6321a5d0-2edc-51bc-8d83-58f3565d3348",
              "score": 0.37641048,
              "payload": {
                "filePath": "batch_config.json",
                "codeChunk": "\"ollama_model\": \"dengcao/Qwen3-Embedding-0.6B:F16\"",
                "startLine": 3,
                "endLine": 3,
                "type": "pair"
              }
            }
          ]
        }
      ],
      "file_types": [
        {
          "test_type": "file_type_.py",
          "query": "Python code",
          "min_score": 0.1,
          "max_results": 5,
          "status": "success",
          "results_count": 5,
          "valid_results_count": 5,
          "response_time": 51.65910720825195,
          "timestamp": "2025-08-24T17:42:01.093017",
          "results_sample": [
            {
              "id": "8e2be9fd-cbb9-544e-9daa-e03b5018e7df",
              "score": 0.5042435,
              "payload": {
                "filePath": "code_index.json",
                "codeChunk": "\"workspace_path\": \"/home/james/kanban_frontend/RESEARCH/kilocode-main\"",
                "startLine": 2,
                "endLine": 2,
                "type": "pair"
              }
            },
            {
              "id": "e85f45d8-e4be-5a43-9819-60a16b1d16c5",
              "score": 0.49087507,
              "payload": {
                "filePath": "src/code_index/chunking.py",
                "codeChunk": "def chunk(self, text: str, file_path: str, file_hash: str) -> List[CodeBlock]:\n        \"\"\"Chunk text into a list of CodeBlock objects.\"\"\"\n        pass",
                "startLine": 21,
                "endLine": 23,
                "type": "function_definition"
              }
            },
            {
              "id": "456d1247-811a-5fa8-be8a-a8fa5683b2b7",
              "score": 0.47968125,
              "payload": {
                "filePath": "search_with_original_model.json",
                "codeChunk": "\"workspace_path\": \"/home/james/kanban_frontend/code_index\"",
                "startLine": 2,
                "endLine": 2,
                "type": "pair"
              }
            }
          ]
        },
        {
          "test_type": "file_type_.js",
          "query": "JavaScript code",
          "min_score": 0.1,
          "max_results": 5,
          "status": "success",
          "results_count": 5,
          "valid_results_count": 5,
          "response_time": 55.43971061706543,
          "timestamp": "2025-08-24T17:42:01.148483",
          "results_sample": [
            {
              "id": "f7f55e73-3924-5dde-b8ad-5f39c996d28c",
              "score": 0.46776152,
              "payload": {
                "filePath": "current_config.json",
                "codeChunk": "\"workspace_path\": \"/home/james/kanban_frontend/code_index\"",
                "startLine": 2,
                "endLine": 2,
                "type": "pair"
              }
            },
            {
              "id": "ab441da7-e14b-5ba4-954b-98a9fa0630d9",
              "score": 0.46776152,
              "payload": {
                "filePath": "local_code_index.json",
                "codeChunk": "\"workspace_path\": \"/home/james/kanban_frontend/code_index\"",
                "startLine": 2,
                "endLine": 2,
                "type": "pair"
              }
            },
            {
              "id": "456d1247-811a-5fa8-be8a-a8fa5683b2b7",
              "score": 0.46776152,
              "payload": {
                "filePath": "search_with_original_model.json",
                "codeChunk": "\"workspace_path\": \"/home/james/kanban_frontend/code_index\"",
                "startLine": 2,
                "endLine": 2,
                "type": "pair"
              }
            }
          ]
        },
        {
          "test_type": "file_type_.ts",
          "query": "TypeScript code",
          "min_score": 0.1,
          "max_results": 5,
          "status": "success",
          "results_count": 5,
          "valid_results_count": 5,
          "response_time": 65.14811515808105,
          "timestamp": "2025-08-24T17:42:01.213676",
          "results_sample": [
            {
              "id": "41a92dec-c42f-58fd-8b7b-2f92d7b1a60a",
              "score": 0.48845822,
              "payload": {
                "filePath": "docs/enhancement_summary.md",
                "codeChunk": "- **Multi-Layer Pattern Management**: \n  - Community templates (GitHub gitignore patterns)\n  - Project conventions (.gitignore files)\n  - Global user preferences\n  - Adaptive learning (future enhancement)\n- **Fast Pattern Matching**: Efficient file filtering with comprehensive coverage\n\n#### Benefits:\n- **Reduced Indexing Noise**: Automatically filters out irrelevant files\n- **Community-Powered**: Leverages GitHub's extensive gitignore templates\n- **Smart Defaults**: Zero configuration required for most projects\n\n### 3. Semantic Code Chunking with Tree-sitter\n**Status**: \u2705 **Completed**\n\n#### Key Features:\n- **Language-Aware Parsing**: Uses Tree-sitter grammars for 20+ languages\n- **Semantic Block Extraction**: Functions, classes, methods instead of arbitrary lines\n- **Performance Optimized**: Smart filtering, size limits, and caching\n- **Configurable Integration**: Toggle via `use_tree_sitter` and `chunking_strategy`\n- **KiloCode Compatible**: Seamless integration with existing workflows\n\n#### Benefits:\n- **Improved Search Quality**: Semantic chunks provide better context for searches\n- **Language Awareness**: Proper AST traversal for each supported language",
                "startLine": 29,
                "endLine": 53,
                "type": "chunk"
              }
            },
            {
              "id": "0d1495e6-5266-5acb-bfc2-6029e2a90fd9",
              "score": 0.47631627,
              "payload": {
                "filePath": "docs/README.md",
                "codeChunk": "# Code Index Tool\n\nA standalone code indexing tool that uses Ollama for embeddings and Qdrant for vector storage, based on the kilocode code-index functionality.\n\n## Features\n\n- Index code files from any directory\n- Generate embeddings using Ollama\n- Store embeddings in Qdrant vector database\n- Search indexed code using semantic search\n- Support for multiple programming languages including Rust, TypeScript, Vue, and SurrealDB Query Language (Surql)\n- File change detection to avoid reprocessing\n- Configurable Ollama and Qdrant endpoints\n- Config-first embedding length (required via config.embedding_length)\n- Token-based chunking option using LangChain TokenTextSplitter with approximate line mapping\n- Auto-extensions discovery via Pygments (augment supported extensions)\n- Configurable embed timeout (config/env/CLI), timeout logging, and retry-list processing\n- Exclude arbitrary files with a newline-separated path list\n\n## Requirements\n\n- Python 3.13+\n- Ollama with embedding models\n- Qdrant server\n- `uv` for environment management (recommended)\n\n## Installation\n\n```bash\n# Clone the repository\ngit clone <repository-url>\ncd code-index-tool",
                "startLine": 1,
                "endLine": 32,
                "type": "chunk"
              }
            },
            {
              "id": "72cec4e1-c9e0-5e6e-a7b5-27a3e093b58e",
              "score": 0.46952474,
              "payload": {
                "filePath": "docs/quick_start.md",
                "codeChunk": "code-index search --config treesitter_config.json \"database connection\"\n\n# Search with higher minimum score for more precise results\ncode-index search --min-score 0.6 \"REST API endpoint\"\n```\n\n### Advanced Search Options\n```bash\n# Search with more results\ncode-index search --max-results 100 \"error handling\"\n\n# Search specific workspace\ncode-index search --workspace /path/to/your/project \"configuration loading\"\n```\n\n## KiloCode Integration\n\n### Compatibility Benefits\nWhen you index a workspace with our tool, KiloCode will:\n\n1. \u2705 **Recognize** the collection as already indexed\n2. \u2705 **Use** our semantic chunks for `code_search`\n3. \u2705 **Skip** re-indexing the workspace\n4. \u2705 **Benefit** from our enhanced ignore patterns\n5. \u2705 **Share** the same Qdrant collections\n\n### Verification\n```bash\n# Index with our tool\ncode-index index --workspace /path/to/your/project --use-tree-sitter\n\n# Check that collection was created\ncode-index collections list\n\n# Open the same workspace in KiloCode - it should:\n# 1. Generate the same collection name\n# 2. Find the collection already exists\n# 3. Recognize it as valid\n# 4. Use our semantic chunks for searches\n# 5. NOT re-index the workspace",
                "startLine": 124,
                "endLine": 163,
                "type": "chunk"
              }
            }
          ]
        },
        {
          "test_type": "file_type_.md",
          "query": "Markdown code",
          "min_score": 0.1,
          "max_results": 5,
          "status": "success",
          "results_count": 5,
          "valid_results_count": 5,
          "response_time": 69.70667839050293,
          "timestamp": "2025-08-24T17:42:01.283422",
          "results_sample": [
            {
              "id": "7065397b-7005-5c47-b676-d7ac449367a8",
              "score": 0.55271876,
              "payload": {
                "filePath": "tests/test_search_specific_query.py",
                "codeChunk": "    print(f\"Generating embedding for query: '{query}'\")\n    try:\n        embedding_response = embedder.create_embeddings([query])\n        query_vector = embedding_response[\"embeddings\"][0]\n        print(f\"\u2713 Embedding generated successfully, dimensions: {len(query_vector)}\")\n    except Exception as e:\n        print(f\"Error generating embedding for query: {e}\")\n        return\n    \n    # Search vector store\n    print(\"Searching vector store...\")\n    try:\n        results = vector_store.search(\n            query_vector=query_vector,\n            min_score=0.2,  # Lower threshold to see more results\n            max_results=10\n        )\n        print(f\"\u2713 Search completed, found {len(results)} results\")\n    except Exception as e:\n        print(f\"Error searching vector store: {e}\")\n        return\n    \n    # Display results\n    if not results:\n        print(\"No results found.\")\n        return\n    \n    print(f\"All results:\")\n    print(\"-\" * 80)\n    \n    for i, result in enumerate(results, 1):\n        payload = result.get(\"payload\", {})\n        file_path = payload.get(\"file_path\", \"Unknown\")\n        start_line = payload.get(\"start_line\", 0)\n        end_line = payload.get(\"end_line\", 0)",
                "startLine": 38,
                "endLine": 72,
                "type": "chunk"
              }
            },
            {
              "id": "8e2be9fd-cbb9-544e-9daa-e03b5018e7df",
              "score": 0.48128727,
              "payload": {
                "filePath": "code_index.json",
                "codeChunk": "\"workspace_path\": \"/home/james/kanban_frontend/RESEARCH/kilocode-main\"",
                "startLine": 2,
                "endLine": 2,
                "type": "pair"
              }
            },
            {
              "id": "41a92dec-c42f-58fd-8b7b-2f92d7b1a60a",
              "score": 0.4718243,
              "payload": {
                "filePath": "docs/enhancement_summary.md",
                "codeChunk": "- **Multi-Layer Pattern Management**: \n  - Community templates (GitHub gitignore patterns)\n  - Project conventions (.gitignore files)\n  - Global user preferences\n  - Adaptive learning (future enhancement)\n- **Fast Pattern Matching**: Efficient file filtering with comprehensive coverage\n\n#### Benefits:\n- **Reduced Indexing Noise**: Automatically filters out irrelevant files\n- **Community-Powered**: Leverages GitHub's extensive gitignore templates\n- **Smart Defaults**: Zero configuration required for most projects\n\n### 3. Semantic Code Chunking with Tree-sitter\n**Status**: \u2705 **Completed**\n\n#### Key Features:\n- **Language-Aware Parsing**: Uses Tree-sitter grammars for 20+ languages\n- **Semantic Block Extraction**: Functions, classes, methods instead of arbitrary lines\n- **Performance Optimized**: Smart filtering, size limits, and caching\n- **Configurable Integration**: Toggle via `use_tree_sitter` and `chunking_strategy`\n- **KiloCode Compatible**: Seamless integration with existing workflows\n\n#### Benefits:\n- **Improved Search Quality**: Semantic chunks provide better context for searches\n- **Language Awareness**: Proper AST traversal for each supported language",
                "startLine": 29,
                "endLine": 53,
                "type": "chunk"
              }
            }
          ]
        },
        {
          "test_type": "file_type_.json",
          "query": "JSON code",
          "min_score": 0.1,
          "max_results": 5,
          "status": "success",
          "results_count": 5,
          "valid_results_count": 5,
          "response_time": 57.4185848236084,
          "timestamp": "2025-08-24T17:42:01.340886",
          "results_sample": [
            {
              "id": "21e54fc0-6969-5c30-9c41-f4adb18c4f54",
              "score": 0.46258736,
              "payload": {
                "filePath": "docs/quick_start.md",
                "codeChunk": "code-index collections list\n\n# View detailed information about a collection\ncode-index collections info ws-491a59846b84697a\n\n# Delete a collection (careful - this removes all data!)\ncode-index collections delete ws-491a59846b84697a\n\n# Prune old collections to free up storage\ncode-index collections prune --older-than 30\n```\n\n## Configuration Examples\n\n### Basic Configuration with Tree-sitter\n```json\n{\n  \"ollama_base_url\": \"http://localhost:11434\",\n  \"ollama_model\": \"nomic-embed-text:latest\",\n  \"qdrant_url\": \"http://localhost:6333\",\n  \"workspace_path\": \".\",\n  \"extensions\": [\".py\", \".js\", \".ts\", \".rs\", \".go\", \".java\"],\n  \"max_file_size_bytes\": 1048576,\n  \"batch_segment_threshold\": 60,\n  \"search_min_score\": 0.4,\n  \"search_max_results\": 50,\n  \"embedding_length\": 768,\n  \"use_tree_sitter\": true,\n  \"chunking_strategy\": \"treesitter\",\n  \"tree_sitter_max_file_size_bytes\": 524288,\n  \"tree_sitter_skip_test_files\": true,\n  \"tree_sitter_skip_patterns\": [\n    \"*.min.js\", \"*.bundle.js\", \"*.min.css\",\n    \"package-lock.json\", \"yarn.lock\",\n    \"target/\", \"build/\", \"dist/\", \"node_modules/\"\n  ]\n}\n```\n\n### Advanced Configuration with Ignore Patterns\n```json",
                "startLine": 44,
                "endLine": 84,
                "type": "chunk"
              }
            },
            {
              "id": "8168407b-c422-5f6f-b7bf-e41c58fac0fb",
              "score": 0.41798958,
              "payload": {
                "filePath": "code_index.json",
                "codeChunk": "\"ollama_model\": \"dengcao/Qwen3-Embedding-0.6B:F16\"",
                "startLine": 4,
                "endLine": 4,
                "type": "pair"
              }
            },
            {
              "id": "6321a5d0-2edc-51bc-8d83-58f3565d3348",
              "score": 0.41798958,
              "payload": {
                "filePath": "batch_config.json",
                "codeChunk": "\"ollama_model\": \"dengcao/Qwen3-Embedding-0.6B:F16\"",
                "startLine": 3,
                "endLine": 3,
                "type": "pair"
              }
            }
          ]
        },
        {
          "test_type": "file_type_.rs",
          "query": "Rust code",
          "min_score": 0.1,
          "max_results": 5,
          "status": "success",
          "results_count": 5,
          "valid_results_count": 5,
          "response_time": 51.32341384887695,
          "timestamp": "2025-08-24T17:42:01.392234",
          "results_sample": [
            {
              "id": "41a92dec-c42f-58fd-8b7b-2f92d7b1a60a",
              "score": 0.4691835,
              "payload": {
                "filePath": "docs/enhancement_summary.md",
                "codeChunk": "- **Multi-Layer Pattern Management**: \n  - Community templates (GitHub gitignore patterns)\n  - Project conventions (.gitignore files)\n  - Global user preferences\n  - Adaptive learning (future enhancement)\n- **Fast Pattern Matching**: Efficient file filtering with comprehensive coverage\n\n#### Benefits:\n- **Reduced Indexing Noise**: Automatically filters out irrelevant files\n- **Community-Powered**: Leverages GitHub's extensive gitignore templates\n- **Smart Defaults**: Zero configuration required for most projects\n\n### 3. Semantic Code Chunking with Tree-sitter\n**Status**: \u2705 **Completed**\n\n#### Key Features:\n- **Language-Aware Parsing**: Uses Tree-sitter grammars for 20+ languages\n- **Semantic Block Extraction**: Functions, classes, methods instead of arbitrary lines\n- **Performance Optimized**: Smart filtering, size limits, and caching\n- **Configurable Integration**: Toggle via `use_tree_sitter` and `chunking_strategy`\n- **KiloCode Compatible**: Seamless integration with existing workflows\n\n#### Benefits:\n- **Improved Search Quality**: Semantic chunks provide better context for searches\n- **Language Awareness**: Proper AST traversal for each supported language",
                "startLine": 29,
                "endLine": 53,
                "type": "chunk"
              }
            },
            {
              "id": "0b3a78f2-82f0-5309-8d5c-339f522243b0",
              "score": 0.43748942,
              "payload": {
                "filePath": "README.md",
                "codeChunk": "- Configurable parallelization and progress reporting\n\n## Enhanced Features\n\n### Smart Collection Management\n- Automatic collection naming based on workspace paths\n- Persistent metadata storage with workspace path mapping\n- Human-readable collection listing with actual filesystem paths\n- Collection pruning and management commands\n\n### Intelligent Ignore Pattern System\n- Automatic language and framework detection\n- GitHub gitignore template integration for 300+ languages\n- Multi-layer ignore pattern management:\n  - Community templates (GitHub gitignore patterns)\n  - Project conventions (.gitignore files)\n  - Global user preferences\n  - Adaptive learning (future enhancement)\n- Fast file pattern matching with comprehensive coverage\n\n### Semantic Code Chunking with Tree-sitter\n- **Language-aware parsing** for 20+ programming languages\n- **Semantic block extraction** (functions, classes, methods) instead of arbitrary lines\n- **Performance optimized** with smart file filtering and size limits\n- **Configurable integration** via `use_tree_sitter` and `chunking_strategy`\n- **Graceful fallbacks** to line-based chunking when needed\n- **KiloCode compatible** for seamless tool integration",
                "startLine": 23,
                "endLine": 49,
                "type": "chunk"
              }
            },
            {
              "id": "72cec4e1-c9e0-5e6e-a7b5-27a3e093b58e",
              "score": 0.43469146,
              "payload": {
                "filePath": "docs/quick_start.md",
                "codeChunk": "code-index search --config treesitter_config.json \"database connection\"\n\n# Search with higher minimum score for more precise results\ncode-index search --min-score 0.6 \"REST API endpoint\"\n```\n\n### Advanced Search Options\n```bash\n# Search with more results\ncode-index search --max-results 100 \"error handling\"\n\n# Search specific workspace\ncode-index search --workspace /path/to/your/project \"configuration loading\"\n```\n\n## KiloCode Integration\n\n### Compatibility Benefits\nWhen you index a workspace with our tool, KiloCode will:\n\n1. \u2705 **Recognize** the collection as already indexed\n2. \u2705 **Use** our semantic chunks for `code_search`\n3. \u2705 **Skip** re-indexing the workspace\n4. \u2705 **Benefit** from our enhanced ignore patterns\n5. \u2705 **Share** the same Qdrant collections\n\n### Verification\n```bash\n# Index with our tool\ncode-index index --workspace /path/to/your/project --use-tree-sitter\n\n# Check that collection was created\ncode-index collections list\n\n# Open the same workspace in KiloCode - it should:\n# 1. Generate the same collection name\n# 2. Find the collection already exists\n# 3. Recognize it as valid\n# 4. Use our semantic chunks for searches\n# 5. NOT re-index the workspace",
                "startLine": 124,
                "endLine": 163,
                "type": "chunk"
              }
            }
          ]
        },
        {
          "test_type": "file_type_.html",
          "query": "HTML code",
          "min_score": 0.1,
          "max_results": 5,
          "status": "success",
          "results_count": 5,
          "valid_results_count": 5,
          "response_time": 58.149099349975586,
          "timestamp": "2025-08-24T17:42:01.450410",
          "results_sample": [
            {
              "id": "5d29423a-773e-5ba5-bf1f-7c523c9b4bef",
              "score": 0.47760475,
              "payload": {
                "filePath": "tests/test_treesitter_integration.py",
                "codeChunk": "        with open(js_file, \"w\") as f:\n            f.write(\"\"\"\nfunction greet(name) {\n    return `Hello, ${name}!`;\n}\n\nclass Person {\n    constructor(name) {\n        this.name = name;\n    }\n    \n    introduce() {\n        return greet(this.name);\n    }\n}\n\nconst person = new Person(\"Alice\");\nconsole.log(person.introduce());\n\"\"\")\n        \n        # Test configuration with Tree-sitter enabled\n        config = Config()\n        config.use_tree_sitter = True\n        config.chunking_strategy = \"treesitter\"\n        \n        # Initialize parser with appropriate chunking strategy\n        from code_index.chunking import TreeSitterChunkingStrategy\n        chunking_strategy = TreeSitterChunkingStrategy(config)\n        parser = CodeParser(config, chunking_strategy)\n        \n        # Test Python file parsing\n        print(\"\\nTesting Python file parsing...\")\n        python_blocks = parser.parse_file(python_file)\n        print(f\"Found {len(python_blocks)} semantic blocks in Python file\")\n        \n        # Check block types\n        block_types = [block.type for block in python_blocks]\n        print(f\"Block types: {set(block_types)}\")\n        \n        # Look for specific semantic blocks",
                "startLine": 46,
                "endLine": 85,
                "type": "chunk"
              }
            },
            {
              "id": "7065397b-7005-5c47-b676-d7ac449367a8",
              "score": 0.4351723,
              "payload": {
                "filePath": "tests/test_search_specific_query.py",
                "codeChunk": "    print(f\"Generating embedding for query: '{query}'\")\n    try:\n        embedding_response = embedder.create_embeddings([query])\n        query_vector = embedding_response[\"embeddings\"][0]\n        print(f\"\u2713 Embedding generated successfully, dimensions: {len(query_vector)}\")\n    except Exception as e:\n        print(f\"Error generating embedding for query: {e}\")\n        return\n    \n    # Search vector store\n    print(\"Searching vector store...\")\n    try:\n        results = vector_store.search(\n            query_vector=query_vector,\n            min_score=0.2,  # Lower threshold to see more results\n            max_results=10\n        )\n        print(f\"\u2713 Search completed, found {len(results)} results\")\n    except Exception as e:\n        print(f\"Error searching vector store: {e}\")\n        return\n    \n    # Display results\n    if not results:\n        print(\"No results found.\")\n        return\n    \n    print(f\"All results:\")\n    print(\"-\" * 80)\n    \n    for i, result in enumerate(results, 1):\n        payload = result.get(\"payload\", {})\n        file_path = payload.get(\"file_path\", \"Unknown\")\n        start_line = payload.get(\"start_line\", 0)\n        end_line = payload.get(\"end_line\", 0)",
                "startLine": 38,
                "endLine": 72,
                "type": "chunk"
              }
            },
            {
              "id": "41a92dec-c42f-58fd-8b7b-2f92d7b1a60a",
              "score": 0.4045089,
              "payload": {
                "filePath": "docs/enhancement_summary.md",
                "codeChunk": "- **Multi-Layer Pattern Management**: \n  - Community templates (GitHub gitignore patterns)\n  - Project conventions (.gitignore files)\n  - Global user preferences\n  - Adaptive learning (future enhancement)\n- **Fast Pattern Matching**: Efficient file filtering with comprehensive coverage\n\n#### Benefits:\n- **Reduced Indexing Noise**: Automatically filters out irrelevant files\n- **Community-Powered**: Leverages GitHub's extensive gitignore templates\n- **Smart Defaults**: Zero configuration required for most projects\n\n### 3. Semantic Code Chunking with Tree-sitter\n**Status**: \u2705 **Completed**\n\n#### Key Features:\n- **Language-Aware Parsing**: Uses Tree-sitter grammars for 20+ languages\n- **Semantic Block Extraction**: Functions, classes, methods instead of arbitrary lines\n- **Performance Optimized**: Smart filtering, size limits, and caching\n- **Configurable Integration**: Toggle via `use_tree_sitter` and `chunking_strategy`\n- **KiloCode Compatible**: Seamless integration with existing workflows\n\n#### Benefits:\n- **Improved Search Quality**: Semantic chunks provide better context for searches\n- **Language Awareness**: Proper AST traversal for each supported language",
                "startLine": 29,
                "endLine": 53,
                "type": "chunk"
              }
            }
          ]
        },
        {
          "test_type": "file_type_.css",
          "query": "CSS code",
          "min_score": 0.1,
          "max_results": 5,
          "status": "success",
          "results_count": 5,
          "valid_results_count": 5,
          "response_time": 52.14810371398926,
          "timestamp": "2025-08-24T17:42:01.502588",
          "results_sample": [
            {
              "id": "7065397b-7005-5c47-b676-d7ac449367a8",
              "score": 0.41635492,
              "payload": {
                "filePath": "tests/test_search_specific_query.py",
                "codeChunk": "    print(f\"Generating embedding for query: '{query}'\")\n    try:\n        embedding_response = embedder.create_embeddings([query])\n        query_vector = embedding_response[\"embeddings\"][0]\n        print(f\"\u2713 Embedding generated successfully, dimensions: {len(query_vector)}\")\n    except Exception as e:\n        print(f\"Error generating embedding for query: {e}\")\n        return\n    \n    # Search vector store\n    print(\"Searching vector store...\")\n    try:\n        results = vector_store.search(\n            query_vector=query_vector,\n            min_score=0.2,  # Lower threshold to see more results\n            max_results=10\n        )\n        print(f\"\u2713 Search completed, found {len(results)} results\")\n    except Exception as e:\n        print(f\"Error searching vector store: {e}\")\n        return\n    \n    # Display results\n    if not results:\n        print(\"No results found.\")\n        return\n    \n    print(f\"All results:\")\n    print(\"-\" * 80)\n    \n    for i, result in enumerate(results, 1):\n        payload = result.get(\"payload\", {})\n        file_path = payload.get(\"file_path\", \"Unknown\")\n        start_line = payload.get(\"start_line\", 0)\n        end_line = payload.get(\"end_line\", 0)",
                "startLine": 38,
                "endLine": 72,
                "type": "chunk"
              }
            },
            {
              "id": "f7f55e73-3924-5dde-b8ad-5f39c996d28c",
              "score": 0.40676638,
              "payload": {
                "filePath": "current_config.json",
                "codeChunk": "\"workspace_path\": \"/home/james/kanban_frontend/code_index\"",
                "startLine": 2,
                "endLine": 2,
                "type": "pair"
              }
            },
            {
              "id": "456d1247-811a-5fa8-be8a-a8fa5683b2b7",
              "score": 0.40676638,
              "payload": {
                "filePath": "search_with_original_model.json",
                "codeChunk": "\"workspace_path\": \"/home/james/kanban_frontend/code_index\"",
                "startLine": 2,
                "endLine": 2,
                "type": "pair"
              }
            }
          ]
        }
      ],
      "performance": {
        "query": "search",
        "iterations": 5,
        "avg_response_time": 55.67960739135742,
        "min_response_time": 52.11067199707031,
        "max_response_time": 62.14761734008789,
        "std_dev_response_time": 4.046639349853329,
        "avg_result_count": 10,
        "response_times": [
          52.11067199707031,
          54.9008846282959,
          52.610158920288086,
          62.14761734008789,
          56.62870407104492
        ],
        "result_counts": [
          10,
          10,
          10,
          10,
          10
        ]
      },
      "error_cases": [
        {
          "test_type": "error_case",
          "query": "",
          "min_score": 0.1,
          "max_results": 5,
          "status": "expected_failure",
          "error": "Failed to generate embeddings: 500 Server Error: Internal Server Error for url: http://localhost:11434/api/embed",
          "results_count": 0,
          "response_time": 31.27884864807129,
          "timestamp": "2025-08-24T17:42:01.812607"
        },
        {
          "test_type": "error_case",
          "query": "xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx",
          "min_score": 0.1,
          "max_results": 5,
          "status": "success",
          "results_count": 5,
          "valid_results_count": 5,
          "response_time": 225.62861442565918,
          "timestamp": "2025-08-24T17:42:02.038361",
          "results_sample": [
            {
              "id": "cf9d2f1b-5137-5212-8280-c099bc428b63",
              "score": 0.37315872,
              "payload": {
                "filePath": "workspace_list.txt",
                "codeChunk": "/home/james/kanban_frontend/Kanban-backend\n/home/james/Documents/Vibe/VibeTools/ast-agent-analyzer\n/home/james/Documents/Vibe/VibeTools/ast-agent-binary\n/home/james/Documents/Vibe/VibeTools/ast-vibe-db\n/home/james/kanban_frontend/kanban_api\n/home/james/kanban_frontend/Kanban-frontend\n",
                "startLine": 1,
                "endLine": 7,
                "type": "chunk"
              }
            },
            {
              "id": "8168407b-c422-5f6f-b7bf-e41c58fac0fb",
              "score": 0.3509205,
              "payload": {
                "filePath": "code_index.json",
                "codeChunk": "\"ollama_model\": \"dengcao/Qwen3-Embedding-0.6B:F16\"",
                "startLine": 4,
                "endLine": 4,
                "type": "pair"
              }
            },
            {
              "id": "6321a5d0-2edc-51bc-8d83-58f3565d3348",
              "score": 0.3509205,
              "payload": {
                "filePath": "batch_config.json",
                "codeChunk": "\"ollama_model\": \"dengcao/Qwen3-Embedding-0.6B:F16\"",
                "startLine": 3,
                "endLine": 3,
                "type": "pair"
              }
            }
          ]
        },
        {
          "test_type": "error_case",
          "query": "!@#$%^&*()_+-=[]{}|;:,.<>?",
          "min_score": 0.1,
          "max_results": 5,
          "status": "success",
          "results_count": 5,
          "valid_results_count": 5,
          "response_time": 72.6921558380127,
          "timestamp": "2025-08-24T17:42:02.111088",
          "results_sample": [
            {
              "id": "8168407b-c422-5f6f-b7bf-e41c58fac0fb",
              "score": 0.40720832,
              "payload": {
                "filePath": "code_index.json",
                "codeChunk": "\"ollama_model\": \"dengcao/Qwen3-Embedding-0.6B:F16\"",
                "startLine": 4,
                "endLine": 4,
                "type": "pair"
              }
            },
            {
              "id": "53cbb6db-63df-5702-9749-47821640e26d",
              "score": 0.40720832,
              "payload": {
                "filePath": "search_with_original_model.json",
                "codeChunk": "\"ollama_model\": \"dengcao/Qwen3-Embedding-0.6B:F16\"",
                "startLine": 4,
                "endLine": 4,
                "type": "pair"
              }
            },
            {
              "id": "6321a5d0-2edc-51bc-8d83-58f3565d3348",
              "score": 0.40720832,
              "payload": {
                "filePath": "batch_config.json",
                "codeChunk": "\"ollama_model\": \"dengcao/Qwen3-Embedding-0.6B:F16\"",
                "startLine": 3,
                "endLine": 3,
                "type": "pair"
              }
            }
          ]
        },
        {
          "test_type": "error_case",
          "query": "caf\u00e9 r\u00e9sum\u00e9 na\u00efve",
          "min_score": 0.1,
          "max_results": 5,
          "status": "success",
          "results_count": 5,
          "valid_results_count": 5,
          "response_time": 55.634498596191406,
          "timestamp": "2025-08-24T17:42:02.166747",
          "results_sample": [
            {
              "id": "8168407b-c422-5f6f-b7bf-e41c58fac0fb",
              "score": 0.36479083,
              "payload": {
                "filePath": "code_index.json",
                "codeChunk": "\"ollama_model\": \"dengcao/Qwen3-Embedding-0.6B:F16\"",
                "startLine": 4,
                "endLine": 4,
                "type": "pair"
              }
            },
            {
              "id": "6321a5d0-2edc-51bc-8d83-58f3565d3348",
              "score": 0.36479083,
              "payload": {
                "filePath": "batch_config.json",
                "codeChunk": "\"ollama_model\": \"dengcao/Qwen3-Embedding-0.6B:F16\"",
                "startLine": 3,
                "endLine": 3,
                "type": "pair"
              }
            },
            {
              "id": "bebb0a11-3a42-593a-a198-c7d79341ea93",
              "score": 0.36479083,
              "payload": {
                "filePath": "kanban_api_config.json",
                "codeChunk": "\"ollama_model\": \"dengcao/Qwen3-Embedding-0.6B:F16\"",
                "startLine": 4,
                "endLine": 4,
                "type": "pair"
              }
            }
          ]
        },
        {
          "test_type": "error_case",
          "query": "def function(): return True",
          "min_score": 0.1,
          "max_results": 5,
          "status": "success",
          "results_count": 5,
          "valid_results_count": 5,
          "response_time": 63.37451934814453,
          "timestamp": "2025-08-24T17:42:02.230151",
          "results_sample": [
            {
              "id": "c118b43e-4fbb-58e3-ac2e-0e1b7c40aa10",
              "score": 0.62934864,
              "payload": {
                "filePath": "src/code_index/vector_store.py",
                "codeChunk": "def collection_exists(self) -> bool:\n        \"\"\"Check if the collection exists.\"\"\"\n        try:\n            collections = self.client.get_collections()\n            return self.collection_name in [collection.name for collection in collections.collections]\n        except Exception:\n            return False",
                "startLine": 359,
                "endLine": 365,
                "type": "function_definition"
              }
            },
            {
              "id": "42ae8b6e-f93e-5bda-a17d-252c67676750",
              "score": 0.6232496,
              "payload": {
                "filePath": "src/code_index/utils.py",
                "codeChunk": "def is_binary_file(file_path: str) -> bool:\n    \"\"\"Check if a file is binary by reading a sample of its content.\"\"\"\n    try:\n        with open(file_path, \"rb\") as f:\n            chunk = f.read(1024)\n            if b\"\\x00\" in chunk:\n                return True\n            # Check if the chunk contains mostly printable characters\n            printable_chars = sum(1 for byte in chunk if 32 <= byte <= 126 or byte in (9, 10, 13))\n            return printable_chars / len(chunk) < 0.7 if chunk else False\n    except (IOError, OSError):\n        # If we can't read the file, assume it's binary\n        return True",
                "startLine": 19,
                "endLine": 31,
                "type": "function_definition"
              }
            },
            {
              "id": "587d64a0-8cff-5e48-bc9d-f5b483597ce4",
              "score": 0.61499405,
              "payload": {
                "filePath": "src/code_index/chunking.py",
                "codeChunk": "def _should_process_file_for_treesitter(self, file_path: str) -> bool:\n        \"\"\"Apply smart filtering like ignore patterns.\"\"\"\n        # First check if this is a source code file that Tree-sitter can handle\n        language_key = self._get_language_key_for_path(file_path)\n        if not language_key:\n            return False  # Not a supported language\n\n        skip_test_files = getattr(self.config, \"tree_sitter_skip_test_files\", True)\n        if skip_test_files:\n            test_patterns = ['test', 'spec', '_test', 'tests']\n            filename = os.path.basename(file_path).lower()\n            # Only skip if the filename contains test patterns in a way that suggests it's a test file\n            # but don't skip files that just have \"test\" as part of their normal name\n            if any(\n                filename == pattern or  # exact match\n                filename.startswith(f\"{pattern}_\") or  # test_something.py\n                filename.endswith(f\"_{pattern}\") or  # something_test.py\n                f\"_{pattern}_\" in filename or  # something_test_something.py\n                filename.endswith(f\".{pattern}\")  # something.test.py\n                for pattern in test_patterns\n            ):\n                return False\n\n        skip_examples = getattr(self.config, \"tree_sitter_skip_examples\", True)\n        if skip_examples:\n            example_patterns = ['example', 'sample', 'demo']\n            filename = os.path.basename(file_path).lower()\n            # Only skip if the entire filename suggests it's an example file\n            if any(filename.startswith(pattern) or filename.endswith(pattern) or f\"_{pattern}\" in filename for pattern in example_patterns):\n                return False\n\n        skip_patterns = getattr(self.config, \"tree_sitter_skip_patterns\", [])\n        for pattern in skip_patterns:\n            if pattern in file_path or file_path.endswith(pattern.lstrip('*')):\n                return False\n\n        generated_dirs = ['target/', 'build/', 'dist/', 'node_modules/', '__pycache__/']\n        if any(gen_dir in file_path for gen_dir in generated_dirs):\n            return False\n\n        return True",
                "startLine": 291,
                "endLine": 331,
                "type": "function_definition"
              }
            }
          ]
        }
      ]
    },
    "tree_sitter": {}
  },
  "performance_metrics": {
    "general_response_times": [],
    "tree_sitter_metrics": {}
  },
  "recommendations": [
    "Enable Tree-sitter semantic chunking for improved search quality",
    "Use the provided configuration as a baseline for production",
    "Monitor semantic result ratios for continuous improvement",
    "Consider expanding Tree-sitter language support for better coverage"
  ]
}